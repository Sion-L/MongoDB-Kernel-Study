# 1. 设计模式

## 1.1 装饰器模式

### 什么是装饰器
在软件设计中，装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。     
这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能。这种模式通常用来为现有对象添加装饰，但是它不能用于已将对象作为参数传递给构造函数的情形。    

比如在 MongoDB 中定义了 Client 类描述客户端信息，包括 TCP 会话（源端地址，目标端地址）、是否为内部连接，连接 id 等。    
但是除了上述基本信息之外，Client 的认证信息（AuthenticationSession）、权限信息（AuthorizationSession）等也是和自身一一对应的。

常见的解决方法有：    
1. 直接在 Client 中添加认证信息、权限信息等字段，但是这样会破坏类的封装性。    
2. 使用继承的方式，在 Client 基础上添加认证信息、权限信息等类。比如在 Client 基础上添加 AuthenticationClient 等类。 但是如果其他基础类也是用了 AuthenticationSession 信息，也要定义自己的派生类，这样会带来大量的代码冗余。   

装饰器模式可以解决上述问题，通过装饰器模式，可以将认证信息、权限信息等独立出来，然后通过 Client 类的装饰器字段指向认证信息、权限信息等对象，这样既不会破坏类的封装性，代码上也会非常简洁。     

### MongoDB 中的装饰器    
MongoDB 内核中的 Client、OperationContext、ServiceContext 等基础类都使用了装饰器模式。       

#### 核心思路
以基础类为 D，需要给其装饰 T1 和 T2 为例。**核心思路就是给每个 D 对象分配一段内存区域存放 T1 和 T2，并且负责管理 T1 和 T2 的生命周期。**   

主要涉及到以下数据结构：    
- **Decorable**：定义在 [util/decorable.h](https://github.com/mongodb/mongo/blob/r4.2.25/src/mongo/util/decorable.h) 文件中。在定义 D 时，需要继承 public Decorable<D>，表示 D 是一个可装饰的类。代码的其他位置就可以使用 D::declareDecoration<T1> 和 D::declareDecoration<T2> 声明 T1 和 T2 是 D 的 挂件。每次调用 declareDecoration 函数会返回一个 Decoration 对象，这个对象中会记录 T1/T2 装饰在 D 的哪个位置（可以理解为一段堆内存中的偏移），通过不同的 Decoration 对象可以快速找到具体的挂件。                  
- **DecorationRegistry**：定义在 [util/decorable_registry.h](https://github.com/mongodb/mongo/blob/r4.2.25/src/mongo/util/decoration_registry.h) 文件中。当 D 通过前面的步骤声明自己为 Decorable 时，就会实例化一个 DecorationRegistry 对象（static 的），这个对象会完成装饰器模式的主要控制逻辑：比如 declareDecoration 时，会根据 T1/T2 的大小进行对齐后，统计堆 buffer 的总大小，并给 T1/T2 分配具体的位置；在 D 进行构造时，会在指定的内存位置构造 T1/T2 对象；在 D 进行析构时，会调用 T1/T2 的析构函数。      
- **DecorationContainer**：定义在 [util/decorable_container.h](https://github.com/mongodb/mongo/blob/r4.2.25/src/mongo/util/decoration_container.h) 文件中。每个 Decorable 对象都会实例化一个 DecorationContainer 对象，这个对象中会保存 D 的所有挂件。DecorationContainer 本质上是一段堆内存（std::unique_ptr<unsigned char[]>），内存长度由 DecorationRegistry 提供，每当构建 D 对象时，会根据 DecorationRegistry 提供的长度信息进行内存分配。      

#### 用法
以 [util/decorable_test.cpp](https://github.com/mongodb/mongo/blob/r4.2.25/src/mongo/util/decorable_test.cpp) 中的单元测试为例。     
```cpp
// 定义 主类/被装饰类 是可被装饰的
class MyDecorable : public Decorable<MyDecorable> {};

// 定义 装饰器类/挂件
static int numConstructedAs;   // A 被构造的总数
static int numDestructedAs;    // A 被析构的总数
class A {
public:
    A() : value(0) {
        ++numConstructedAs;
    }
    ~A() {
        ++numDestructedAs;
    }
    int value;
};

// 具体的执行逻辑
TEST(DecorableTest, DecorableType) {
    const auto dd1 = MyDecorable::declareDecoration<A>();  // 声明 A 是 MyDecorable 的装饰器，并返回 A 在堆内存上的位置
    const auto dd2 = MyDecorable::declareDecoration<A>();  // 再次声明 A 是 MyDecorable 的装饰器。并返回第 2 个 A 在堆内存上的位置
    const auto dd3 = MyDecorable::declareDecoration<int>();  // 声明 int 是 MyDecorable 的装饰器，并返回 int 在堆内存上的位置
    numConstructedAs = 0;
    numDestructedAs = 0;
    {
        MyDecorable decorable1;  // 构造 MyDecorable 对象
        ASSERT_EQ(2, numConstructedAs);  // 构造了 2 个 A (在内存中顺序排列)
        ASSERT_EQ(0, numDestructedAs);
        MyDecorable decorable2;  // 构造另一个 MyDecorable 对象
        ASSERT_EQ(4, numConstructedAs);  // 构造了 2 个 A (在 decorable2 d的内存中顺序排列)
        ASSERT_EQ(0, numDestructedAs);

        ASSERT_EQ(0, dd1(decorable1).value);  // decorable1 的 第 1 个 A 对象的 value
        ASSERT_EQ(0, dd2(decorable1).value);  // decorable1 的 第 2 个 A 对象的 value
        ASSERT_EQ(0, dd1(decorable2).value);  // decorable2 的 第 1 个 A 对象的 value
        ASSERT_EQ(0, dd2(decorable2).value);  // decorable2 的 第 2 个 A 对象的 value
        ASSERT_EQ(0, dd3(decorable2));  // decorable2 的 int 对象
        dd1(decorable1).value = 1;  // 给上述对象赋值 
        dd2(decorable1).value = 2;
        dd1(decorable2).value = 3;
        dd2(decorable2).value = 4;
        dd3(decorable2) = 5;
        ASSERT_EQ(1, dd1(decorable1).value);  // 再次确认赋值后的对象
        ASSERT_EQ(2, dd2(decorable1).value);
        ASSERT_EQ(3, dd1(decorable2).value);
        ASSERT_EQ(4, dd2(decorable2).value);
        ASSERT_EQ(5, dd3(decorable2));
    }
    ASSERT_EQ(4, numDestructedAs);  // decorable1 和 decorable2 都被析构，每个对象都析构 2 个 A
}
```

#### 构造和析构流程
整体流程如下图所示：
1. 在初始化阶段，使用 declareDecoration 函数声明装饰器，计算装饰器总内存大小，并确定每个装饰器在内存中的位置。
2. 在运行时阶段，在构造主类对象（被装饰的对象）时，会在堆上分配内存空间并在指定位置构造装饰器对象。在析构主对象时则会析构装饰器并释放内存。    

<p align="center">
  <img src="https://github.com/user-attachments/assets/ce2dd6fd-9b9f-40cb-859d-61d71855e38a" width=800>
</p>

## 1.2 单例模式


## 1.3 观察者模式


# 2. 算法和数据结构

## 2.1 WriteConflict 的运用
在前面章节中，提到了 WT 引擎采用乐观锁机制实现高并发。如果 2 个事务同时修改了同 1 条文档，由于 first-update-win 机制，只有一个事务会提交成功，另一个事务会由于 writeConflict 失败并依赖上层的重试。     

**如果利用事务的原子性，再结合 writeConflict 的冲突检测能力，就能在上层应用中实现乐观锁。**        

上述 “乐观锁” 机制在 MongoServer 层的索引中得以广泛使用，下面列举 2 个例子。

### 索引的唯一性检测
在 1.2 章节中，提到了 MongoDB 中索引的格式为： {Key: IndexKey+RecordId, Value: typeBits}, 其中 IndexKey 是索引的 key，RecordId 是文档的唯一id（一般为自增 int64）， typeBits 用于将 KeyString 格式的字符串转回原始类型。     
索引的唯一性检测需要通过 Key 的前缀来判断。    

假设我们对 "a" 字段创建了唯一索引，然后同时插入了 2 条 "a" 字段为 1 的文档：    
- 事务 1：**检测**没有前缀为 "a=1" 的索引，于是往索引中插入记录 {Key: "a=1" + record1, Values: typeBits}.
- 事务 2：**检测**没有前缀为 "a=1" 的索引，于是往索引中插入记录 {Key: "a=1" + record2, Values: typeBits}.

此时，由于 2 个事务都插入成功，导致索引中出现了重复的记录。    

MongoDB 通过构造写冲突的方式来解决上述问题，在上述流程中增加了**额外步骤**：    

- 事务 1：插入 {Key:"a=1", Value: typeBits}, 然后删除之。
- 事务 2：插入 {Key:"a=1", Value: typeBits}, 然后删除之。

通过上述处理，2 个事务出现了写冲突，只有一个事务能够插入成功。而另外一个事务失败后进入重试，然后检测到有 "a=1" 的索引前缀，并给客户端报错。

### 后台建索引的冲突检测
在 MongoDB 早期版本有 background 建索引功能（4.2 之后逐步被更优的 hybrid 模式取代）。      
在 [MongoDB 索引使用总结](https://mp.weixin.qq.com/s/g0mNt73nnFS_xyVGuAPe-g) 中提到一个后台建索引时处理冲突的 case。核心思想是主动构造写冲突，避免索引和表的数据不一致。这里不再赘述。    

## 2.2 为多 CPU 架构而生的 LRU 


## 2.3 为多 CPU 架构而生的 mutex


## 2.4 实时预估数据压缩率
### 问题背景
在 1.3 章介绍 WT 引擎时，提到 WT 引擎会使用压缩算法将内存 page 压缩之后，再按照 4KB 对齐后写入磁盘。      
可以使用 stats() 命令查看表的创建参数：

>mongos> db.coll1.stats().wiredTiger.creationString
access_pattern_hint=none,allocation_size=4KB,app_metadata=(formatVersion=1),assert=(commit_timestamp=none,durable_timestamp=none,read_timestamp=none),block_allocation=best,block_compressor=snappy,cache_resident=false,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=false,extractor=,format=btree,huffman_key=,huffman_value=,ignore_in_memory_cache_size=false,immutable=false,internal_item_max=0,internal_key_max=0,internal_key_truncate=true,internal_page_max=4KB,key_format=q,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=32KB,leaf_value_max=64MB,log=(enabled=false),lsm=(auto_throttle=true,bloom=true,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=false,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_custom=(prefix=,start_generation=0,suffix=),merge_max=15,merge_min=0),memory_page_image_max=0,memory_page_max=10m,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=false,prefix_compression_min=4,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=90,type=file,value_format=u

其中本次要讨论的算法，涉及的参数有：
- **internal_page_max=4KB**：硬盘上 btree 的非叶子节点最大 4KB
- **leaf_page_max=32KB**: 硬盘上 btree 的叶子节点最大 32KB
- **memory_page_max=10m**： 内存中的 page 最大 10MB

> 为什么硬盘上的 page 大小会有 4KB 和 32KB 的限制？    
个人认为：    
1.如果限制太小，则不能发挥硬盘的 IO 能力（硬盘都是按块读取的，而且为了提升 IO 能力都会有一定的 readahead 预读机制）。另外也会导致 btree 的高度更高以及压缩效率降低。    
2.如果限制太大，会导致读放大比较严重。

内存 page 可能比硬盘上的 page(也叫做 block/extent) 大很多，因此在 checkpoint/evict 流程将内存 page 写入硬盘时，**需要先 split 成多个大小合适的 page**，然后再压缩后写入。

<p align="center">
  <img src="https://github.com/user-attachments/assets/dd91f071-fbd9-40cc-92d1-98e19fab7d87" width=600>
</p>

理想的分隔结果是：分隔后的 page 在压缩之后，大小正好等于或者非常接近 internal_page_max 和 leaf_page_max。 这样 padding 所占的比例就会比较小，空间浪费较小。    

但是数据的压缩比例可能是动态变化的，如何准确预估压缩比例并确定分割点，就是本次要讨论的问题。

### 算法实现
每个 btree 都维护了变量，来记录理想情况下，压缩前 page 的原始大小。也就是上文提到的理想分隔位置：    
- maxintlpage_precomp：理想情况下，非叶子节点 page 的原始大小，初始值 4KB.
- maxleafpage_precomp：理想情况下，叶子节点 page 的原始大小，初始值 32KB * 4 = 128KB.

每次内存 page 会根据上述 precomp 值进行分隔。然后在压缩并写入硬盘后，根据实际压缩大小以及数据原始大小，再去跟新 precomp 值。    

简单来说，就是按照压缩后的大小，计算到 internal_page_max 或 leaf_page_max 的距离是否超过 10%，来动态调整。      
以 leaf page 为例，如果本次压缩后的大小为 28KB，距离 32KB 有 4KB 差距，大于 32KB * 10%. 此时 precomp 值需要向上调整。    
反之，需要向下调整。    

核心代码参考 [__rec_compression_adjust](https://github.com/mongodb/mongo/blob/r4.2.25/src/third_party/wiredtiger/src/reconcile/rec_write.c#L1755) ：
```c
/*
 * __rec_compression_adjust --
 *     Adjust the pre-compression page size based on compression results.
 */
static inline void
__rec_compression_adjust(WT_SESSION_IMPL *session, uint32_t max, size_t compressed_size,
  bool last_block, uint64_t *adjustp)
{
    WT_BTREE *btree;
    uint64_t adjust, current, new;
    u_int ten_percent;

    btree = S2BT(session);
    ten_percent = max / 10;   // 是否调整的参考

    /*
     * Changing the pre-compression size updates a shared memory location
     * and it's not uncommon to be pushing out large numbers of pages from
     * the same file. If compression creates a page larger than the target
     * size, decrease the pre-compression size. If compression creates a
     * page smaller than the target size, increase the pre-compression size.
     * Once we get under the target size, try and stay there to minimize
     * shared memory updates, but don't go over the target size, that means
     * we're writing bad page sizes.
     *	Writing a shared memory location without a lock and letting it
     * race, minor trickiness so we only read and write the value once.
     */
    WT_ORDERED_READ(current, *adjustp);
    WT_ASSERT(session, current >= max);

    if (compressed_size > max) {  // 压缩后大小大于目标值，向下调整
        /*
         * The compressed size is GT the page maximum. Check if the pre-compression size is larger
         * than the maximum. If 10% of the page size larger than the maximum, decrease it by that
         * amount. Else if it's not already at the page maximum, set it there.
         *
         * Note we're using 10% of the maximum page size as our test for when to adjust the
         * pre-compression size as well as the amount by which we adjust it. Not updating the value
         * when it's close to the page size keeps us from constantly updating a shared memory
         * location, and 10% of the page size is an OK step value as well, so we use it in both
         * cases.
         */
        adjust = current - max;
        if (adjust > ten_percent)
            new = current - ten_percent;
        else if (adjust != 0)
            new = max;
        else
            return;
    } else {  // 压缩后大小小于目标值，向上调整
        /*
         * The compressed size is LTE the page maximum.
         *
         * Don't increase the pre-compressed size on the last block, the last block might be tiny.
         *
         * If the compressed size is less than the page maximum by 10%, increase the pre-compression
         * size by 10% of the page, or up to the maximum in-memory image size.
         *
         * Note we're using 10% of the maximum page size... see above.
         */
        if (last_block || compressed_size > max - ten_percent)
            return;

        adjust = current + ten_percent;
        if (adjust < btree->maxmempage_image)
            new = adjust;
        else if (current != btree->maxmempage_image)
            new = btree->maxmempage_image;
        else
            return;
    }
    // 调整完成，更新 precomp 值
    *adjustp = new;
}
```

# 3. 参考文档
1. https://www.runoob.com/design-pattern/decorator-pattern.html
2. https://github.com/mongodb/mongo/tree/r4.2.25
3. MongoDB 索引使用总结：https://mp.weixin.qq.com/s/g0mNt73nnFS_xyVGuAPe-g
