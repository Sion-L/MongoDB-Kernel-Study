>基于作者公开发布的博客进行补充整理：https://mp.weixin.qq.com/s/FxaUhtRho5YOpCFgmk1Mdg

# 1. 导语
并发控制是数据库充分利用多核硬件的关键技术。当我们谈论一个数据库的请求处理耗时，以及能支撑多大吞吐时，优先想到的一点就是数据库能支持多少并发。    
本文将从 MongoDB Server 和 WiredTiger 存储引擎 2 个层面，探讨 MongoDB 中如何进行锁与并发控制。    

# 2. MongoDB 的并发控制
## 2.1 引子：从 MongoDB 的慢日志引入
在我们日常的数据库使用中，经常会与慢日志打交道。而在使用 MongoDB 时，慢日志也常作为 MongoDB 读写性能的衡量标志之一。笔者刚入职时，自己也刚开始接触数据库中的慢日志概念，不经会发出疑问：   

什么是慢日志？    

慢日志的全称为“Slow Query Log”，正如其英文直译，代表着对返回较慢的查询请求的日志记录，最开始是 MySQL 中对执行较慢查询的统计，主要用于记录 MySQL 中执行时间超过指定时间的 SQL 语句；通过查询慢日志，我们可以查找出哪些语句的执行效率较低，并进行针对性的查询优化。    

MongoDB 中慢日志的概念与 MySQL 中的相同，一般将执行时间大于 100ms 的请求称为慢请求，内核会在执行时统计请求的执行时间，并记录下执行时间大于 100ms 的请求相关信息，打印至内核运行日志中，记录为慢日志。通过查看 MongoDB 的慢日志，我们可以获得对应请求与内核当前运行状态的诸多信息，并可以依次为依据做出对应的优化策略。    

MongoDB 也可以通过多种方式采集、记录慢请求的相关信息。    
如在 MongoDB 中，可以通过以下语句设定 Database Profiler 用于过滤、采集请求，用于慢操作的分析。    
```
# 查看Databaseprofiler配置
db.getProfilingStatus()

# 设置Databaseprofiler用于采集慢请求
db.setProfilingLevel(<level>, <options>)
```
其中 level 代表 profiling 的等级，有如下三个等级：
- 0：不开启 profiler（默认不开启）。
- 1：开启 profiler 采集慢请求（默认采集 100ms 以上）。
- 2：开启 profiler 采集所有的操作。

options 则包含以下选项：
- slowMs：慢请求判断毫秒数，只有大于 slowMs 的请求才会被 profiler 标记并记录为慢请求，默认 100ms。    
- sampleRate：采集慢操作的采样率。    
- filter：采样的过滤规则。    

在设置 Profiler 后，满足条件的慢请求将会被记录在 system.profile 表中，该表为一个 capped collection，可以通过 db.system.profile.find() 来过滤与查询慢请求的记录，举个例子：    
```

>db.system.profile.find().pretty()
{
   "op" : "query", # 操作类型，可为command、count、distinct、geoNear、getMore、group、insert、mapReduce、query、remove、update
   "ns" : "test.report", # 操作的目标namespace库表
   "command" : { # 操作的具体command
      "find" : "report",
      ......
   },
   "cursorid" : 33629063128, # query与getMore使用的cursor id
   "keysExamined" : 101, # 为执行操作扫描的索引键数量
   "docsExamined" : 101, # 为执行操作扫描的文档数据
   "fromMultiPlanner" : true,
   "numYield" : 2, # 执行操作时让其他操作完成的次数
   "nreturned" : 101, # 返回的文档数量
   "queryHash" : "811451DD", # 查询的hash
   "planCacheKey" : "759981BA", # 查询计划的key
   "locks" : { # 锁信息
      "Global" : { # 全局锁
         "acquireCount" : {
            "r" : NumberLong(3),
            "w" : NumberLong(3)
         }
      },
      "Database" : { # Database锁
         "acquireCount" : { "r" : NumberLong(3) },
         "acquireWaitCount" : { "r" : NumberLong(1) },
         "timeAcquiringMicros" : { "r" : NumberLong(69130694) }
      },
      "Collection" : { # Collection锁
         "acquireCount" : { "r" : NumberLong(3) }
      }
   },
   "storage" : { # 存储情况
      "data" : {
         "bytesRead" : NumberLong(14736), # 从磁盘中读取的数据大小
         "timeReadingMicros" : NumberLong(17) # 从磁盘读取数据的耗时
      }
   },
   "responseLength" : 1305014, # response的大小
   "protocol" : "op_msg", # 消息的协议
   "millis" : 69132, # 执行时间，milliseconds
   "planSummary" : "IXSCAN { a: 1, _id: -1 }", # 执行计划，这里代表走索引查询
   "execStats" : { # 操作执行的详细步骤信息
      "stage" : "FETCH", # 操作类型，如COLLSCAN、IXSCAN、FETCH
      "nReturned" : 101, # 返回文档数
      ......
   },
   "ts" : ISODate("2019-01-14T16:57:33.450Z"), # 时间戳
   "client" : "127.0.0.1", # 客户端信息
   "appName" : "MongoDB Shell", # appName
   "allUsers" : [
      {
         "user" : "someuser",
         "db" : "admin"
      }
   ],
   "user" : "someuser@admin" # 执行的用户信息
}
```
上述信息记录了慢操作的详细的一些信息，可方便的用于慢操作的查询与分析，如以下几点：    
- command：记录的请求的内容，可以帮助我们分析慢请求的原因。
- locks：请求与锁的相关信息，执行请求需要获取的锁，以及锁排队等待、获取时长等信息。
- writeConflicts（只有写请求）：写冲突，在同时写一个文档时即会造成些冲突。
- millis：慢请求最终执行时长。
- planSummary：如执行 COLLSCAN 全表扫就会比执行 IXSCAN 索引话费更多的资源与时间。
- execStats：执行计划的具体执行情况，方便得知请求的执行全貌。  


从以上几个方面分析，可以大致得知请求的执行情况，用于分析慢请求产生的原因。一般而言，慢请求的产生无非以下几点原因：    
- CPU负载高：如频繁的认证/建链接会使大量CPU消耗，导致请求执行慢。
- 等锁/锁冲突：一些请求需要获取锁，而如果有其他请求拿到锁未释放，则会导致请求执行慢。    
- 全表扫描：查询未走索引，导致全表扫描，会导致请求执行慢。    
- 内存排序：与上述情况类似，未走索引的情况下内存排序导致请求执行慢。    

但开启分析器 Profiler 是需要一些代价的（如影响内核性能），且一般来说默认关闭，故在处理线上问题时，我们往往只能拿到内核日志中记录的慢日志信息。   

一条典型的 MongoDB 慢日志举例如下（内核版本大于 4.4 的日志）：    
```
{
  "t": { # 时间戳
    "$date": "2020-05-20T20:10:08.731+00:00"
  },
  "s": "I", # 日志等级，分为F、E、W、I，分别为Fatal、Error、Warning、Info
  "c": "COMMAND", # 执行请求类型，分为ACCESS、COMMAND、CONTROL、ELECTION、FTDC、GEO、INDEX等
  "id": 51803, # 慢日志的日志id
  "ctx": "conn281", # 链接的信息
  "msg": "Slow query", # 慢日志信息，代表是慢请求
  "attr": { # 参数详情
    "type": "command", # 请求类型
    "ns": "stocks.trades", # Namespace，请求的库表
    "appName": "MongoDB Shell", # client的app name
    "command": { # 请求详情
      "aggregate": "trades", # 请求为aggregate，且在trades表上执行
      ......
    },
    "planSummary": "COLLSCAN", # 请求执行了COLLSCAN
    "cursorid": 1912190691485054700,
    "keysExamined": 0,
    "docsExamined": 1000001, # 查询的文档数，由于是COLLSCAN所以查询较多
    "hasSortStage": true,
    "usedDisk": true,
    "numYields": 1002, # 查询让渡其他请求执行数
    "nreturned": 101, # 返回的文档数，远远小于docsExamined，全表扫消耗了大量时间
    "reslen": 17738,
    "locks": { # 锁信息
      "ReplicationStateTransition": {
        "acquireCount": {
          "w": 1119
        }
      },
      "Global": {
        "acquireCount": {
          "r": 1119
        }
      },
      "Database": {
        "acquireCount": {
          "r": 1119
        }
      },
      "Collection": {
        "acquireCount": {
          "r": 1119
        }
      },
      "Mutex": {
        "acquireCount": {
          "r": 117
        }
      }
    },
    "storage": {
      ......
    },
    "remote": "192.168.14.15:37666",
    "protocol": "op_msg",
    "durationMillis": 22427
  }
}
```
从上述慢请求中，一些信息是比较直观的，如 planSummary 为 COLLSCAN 代表查询走了全表扫，而全表扫描一般意味着性能较差；如 docsExamied 若远大于 nreturned，则代表着请求执行的效率较低，性能较差。而也有一些信息不那么直观，如locks虽然代表了请求的锁信息，但其中又分为不少子项目，第一眼看上去不禁会让人感到疑惑：      
- ReplicationStateTransation、Global、Database、Collection、Mutex 分别代表什么意思？
- W、R、w、r 分别代表什么含义？
- 锁数量的大小意味着什么？
- 不同锁之间是什么关系？有什么联系？
- MongoDB 中的锁是如何实现的？结构如何？
- 我们带着以上问题开始逐步了解 MongoDB 中的锁。

## 2.2 MongoDB 的锁与资源分类
MongoDB 支持并发读写操作，故需要用锁来确保并发时的数据一致性。在 MongoDB 中，不同的请求会对不同的资源执行请求，故加锁的操作也是在不同的资源上进行加锁。通过对资源进行分层与层级管理，以及使用不同类型的锁执行锁机制来避免并发冲突。    

### 2.2.1 资源分类
在 MongoDB 中对资源进行了层级划分，锁本身的 lock_manager 并不区分自己属于哪个资源，且不同层级的资源之间永不互斥（不会互相影响）。一般而言，MongoDB 中的资源按以下类型进行分类，且从上到下优先级依次降低。    
在4.4版本之前（包括），资源分类如下：    
```

enum ResourceType {
    RESOURCE_INVALID = 0,

    RESOURCE_PBWM,  // 并发批量写资源锁

    RESOURCE_RSTL, // 副本集成员状态转换锁，状态包括如STARTUP、PRIMARY、SECONDARY、RECOVERING等

    RESOURCE_GLOBAL, // global操作的资源锁，如reIndex、renameCollection、replSetResizeOplog等操作都会acquire global W 锁

    RESOURCE_DATABASE, // database级别操作的资源锁，如cloneCollectionCapped、collMod、compact、convertToCapped等操作都会acquire databsae W 锁
    RESOURCE_COLLECTION, // collection级别操作的资源锁，如createCollection、createIndexes、drop等操作都会acquire collection W 锁
    RESOURCE_METADATA, // 元数据相关的锁

    RESOURCE_MUTEX, // 剩余的不与存储层相关的其他资源的锁

    ResourceTypesCount
};
```
在4.4版本之后，资源分类如下：    
```

// 资源类型大致与4.4版本之前一致，只是global资源有所变化
enum ResourceType {
    RESOURCE_INVALID = 0,
    RESOURCE_GLOBAL,
    RESOURCE_DATABASE,
    RESOURCE_COLLECTION,
    RESOURCE_METADATA,
    RESOURCE_MUTEX,
    ResourceTypesCount
};

// 使用枚举来表示所有的global资源
enum class ResourceGlobalId : uint8_t {
    kParallelBatchWriterMode,
    kFeatureCompatibilityVersion,
    kReplicationStateTransitionLock,
    kGlobal,

    kNumIds
};
```
从5.0开始，将 RESOURCE_PBWM、RESOURCE_RSTL、RESOURCE_GLOBAL 全部归为了 RESOURCE_GLOBAL，且使用一个 enum 对其进行划分。从5.0开始，还新增了一批 lock-free read 操作，这些操作在其他操作持有同 collection 的排他写锁时也不会被阻塞，如 find、count、distinct、aggregate、listCollections、listIndexes 等，其中 aggregate 中包含对 collection 的写入时，会持有 collection 的意向排他锁。    

以上资源层级自上而下优先级依次降低。为了防止出现死锁，一般而言在对低优先级的资源加锁时，都需要先对更高优先级的资源加意向锁。如：在对 RESOURCE_COLLECTION 加排它锁之前，需要对 RESOURCE_DATABASE以及 RESOURCE_GLOBAL 加意向排他锁。    
<TODO 添加锁继承的示意图>    

故该操作的锁获取情况为：   
```
{
  "locks": {
    "Global": {
      "acquireCount": {
        "w": 1
      }
    },
    "Database": {
      "acquireCount": {
        "w": 1
      }
    },
    "Collection": {
      "acquireCount": {
        "W": 1
      }
    },
  }
}
```

### 2.2.2 锁分类
MongoDB 中不仅对资源进行了层级划分，还对锁的类型进行了划分，如上文中提到的意向锁、排它锁、共享锁等。本节讲述在同一层级资源中，通过划分不同的锁类型，来高效地解决并发关系。    

在 MongoDB 中为了提高并发效率，提供了类似读写锁的模式，即共享锁（Shared, S）（读锁）以及排他锁（Exclusive, X）（写锁），同时，为了解决多层级资源之间的互斥关系，提高多层级资源请求的效率，还在此基础上提供了意向锁（Intent Lock）。即锁可以划分为 4 种类型：    
```
enum LockMode {
    MODE_NONE = 0,
    MODE_IS = 1, //意向共享锁，意向读锁，r
    MODE_IX = 2, // 意向排他锁，意向写锁，w
    MODE_S = 3, // 共享锁，读锁，R
    MODE_X = 4, // 排它锁，写锁，W

    LockModesCount
};
```

有了读写锁，为什么还要再划分意向锁？我们知道在多层级资源加锁过程中，对低层级资源加锁时还需要对高层级资源添加意向锁。由于往往高层级的资源对低层级的资源是包含关系，故加意向锁的操作目的是：在对低层级资源加锁时，通过对上一级资源加意向锁告诉外界，在高级资源中有某个低级资源被添加了锁。    

意向锁有什么用呢？百科上的解释为：    
如果另一个任务企图在某表级别上应用共享或排他锁，则受由第一个任务控制的表级别意向锁的阻塞，第二个任务在锁定该表前不需要检查各个页或行锁，而只需检查表上的意向锁。    

话说的比较绕，举个例子：    
假如有一个操作 A 锁住了某一个 collectionX，此时有另一个操作 B 需要对 DB1 进行操作，而 collectionX 又属于 DB1，此时在操作 B 加锁之前，需要进行以下步骤的 Check：    
- 检查 DB1 的库锁是否被其他操作持有。
- 依次检查 DB1 下所有的 collection，确认是否有其他操作持有其中之一的 collection 锁。    

<TODO 意向锁示意图1>

这里需要遍历所有的次级资源锁进行判断，若某 DB 下有很多的 collection，则遍历拿锁的时间线性增长，故引入了意向锁的概念。当添加意向锁后，操作 A 再给 collectionX 加锁前，还需要给 DB1 加一把意向锁；这样在操作 B 在给 DB1 加锁前，上述 check 步骤变为如下：    
- 检查 DB1 的库锁是否被其他操作持有；
- 检查 DB1 的意向锁是否被其他操作持有。

<TODO 意向锁示意图2>

这样在请求上级资源的锁时，只需要 check 上级资源的意向锁是否被占用，如被占用则意味着有次级资源的锁被占用，这里不必再去遍历所有次级资源的锁占用情况，使锁获取的判断更加高效。    

## 2.3 MongoDB 的锁矩阵


## 2.4 浅入：MongoDB 的锁实现


# 3. WiredTiger 存储引擎的并发控制



# 4. 总结

# 5. 参考文档
1. https://mp.weixin.qq.com/s/FxaUhtRho5YOpCFgmk1Mdg
