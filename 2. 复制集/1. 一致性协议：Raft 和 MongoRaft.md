# 1. 导语
MongoDB 使用多个节点组成副本集保证数据高可靠以及服务高可用。对于自动容错的分布式系统来说，如何保证HA、数据一致性、高吞吐、低延迟、协议易理解（易运维）是系统设计的关键。   
一致性协议（consensus algorithm， 共识算法）就是上述问题的解决方案。

# 2. Raft 和 MongoRaft
目前业界比较流行的一致性协议有 Paxos 和 Raft。[《共识协议的技术变迁》](https://mp.weixin.qq.com/s/UY9TPMcuf0O7xS0kuXTcVw)一文中对一致性算法的发展历程进行了非常通俗易懂的描述。   
Paxos 诞生时间比较早，并使用在 Chubby，ZooKeeper 等系统中，但是协议理解起来比较复杂，学习路径有些陡峭。   
Raft 的诞生实践稍晚，相对 Paxos来说非常好理解。从 [Raft 论文](https://raft.github.io/raft.pdf)也可以看出，从设计之初就考虑了协议的通俗易懂，以及如何指导工程落地。在 etcd，redis 等开源项目中都能看到它的身影。   
正如 Raft 论文中所说，Raft 本身还有很多值得优化的地方，比如日志复制的性能问题等。另外，在实际的成功落地过程中，也有很多边界情况需要考虑。所以，业界很多系统使用的 Raft 算法时都是根据实际情况进行优化后的变种。截止目前，在 [raft.github.io](https://raft.github.io) 中登记的使用了Raft算法的开源项目已经有几十个（比如 TiKV, etcd 等），如果算上没有登记的项目（比如 MongoDB） 应该有上百个。

MongoDB 使用的一致性协议也可以看作是 Raft 协议的一个变种，同样使用了强主模式来定序，使用日志复制到大多数节点来提交请求。但是 MongoDB 在落地过程中，相比于原生 Raft 协议还是有不少改进，比如更丰富的节点状态、乱序提交、Pull-Based 复制模型、链式复制、可调一致性、Logless Reconfig 等。    
正如 MongoDB 官方论文[《Fault-Tolerant Replication with Pull-Based Consensus in MongoDB》 ](https://www.usenix.org/conference/nsdi21/presentation/zhou)中所说，MongoDB 选取 Raft 而没有基于 Paxos 很大一定程度上也是基于工程落地方面的考虑。理论上来说，如果基于 Paxos 实现也是没有问题的。   
MongoDB 一致性协议的[发展历史](https://www.usenix.org/system/files/nsdi21_slides_zhou-siyuan.pdf)如下：   
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/3b514626-b141-45ed-8499-f372c944489f" width=800>   
- MongoDB 1.0 是刀耕火种的时代，需要手动进行 failover.   
- MongoDB 1.6 引入了自动 failover 机制，但是是基于没有证明的私有协议。
- MongoDB 3.2 基于 Raft 重新改造了一致性协议，进行了 TLA+ 证明。同时在改造过程中保留了 MongoDB自身 的 Pull-Based 日志复制模型、链式复制等诸多优秀特性，使得MongoDB 的一致性协议在正确性、效率、性能等各方面都达到了非常高的标准。   

由于 MongoDB 官方已明确说明一致性协议基于 Raft，而且在 [《Design and Analysis of a Logless Dynamic Reconfiguration Protocol》](https://drops.dagstuhl.de/opus/volltexte/2022/15801/pdf/LIPIcs-OPODIS-2021-26.pdf)论文中更是将配置变更算法起名为 MongoRaftReconfig. 因此，为了描述方便，本文统一将 MongoDB 的一致性协议简称为 MongoRaft。

类比是非常好的学习方法。本文首先从原生 Raft 入手，从 Raft 论文简要了解其设计思想和流程。然后结合 MongoDB内核源码、官方论文以及github wiki，重点介绍 MongoDB 的一致性协议，并说明相比原生 Raft 所作的优化及效果。   
结合 Raft 论文对协议做的模块划分，以及我个人的理解。本文的描述将分如下几个模块阐述：   
1. 节点状态及其变迁规则。
2. 日志复制和提交。
3. 如何选主。
4. 配置变更。
5. 持久化保证。
6. 一致性保证。

# 3. 深入分析 MongoRaft
## 3.1 节点角色
Raft 论文中描述了 3 种节点角色：   
- Leader： 主节点，接收读写请求，承担日志复制，请求提交，心跳探活等任务。
- Follower：从节点，接收日志复制和应用，作为一个完整的数据副本。  
- Candidate：Follower长时间没有感知到主节点时，可以变为 Candidate 并发起选举。   

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/33003281-72a3-44b5-8b3e-e826c17490e1" width=400>

此外，论文中也提到了 Follower 节点可以设置 non-voting 属性，不计入大多数提交时的副本数（Learner）。一般在新加入节点时，可以使用这个设置避免数据提交卡顿。  

MongoDB 中包含的节点角色也有主从状态。 其中主节点（Primary）支持读写，从节点（Secondary）支持读（这是和 Raft 不同之处）。另外从节点又[细分](https://github.com/mongodb/mongo/blob/r4.2.24/src/mongo/db/repl/member_state.h#L58-L70)为：  
- Secondary：正常状态下的从节点，支持用户读。  
- Rollback：回滚状态。常见的场景是主节点异常重启后变为从节点，需要将没有复制到其他节点的日志回滚掉。  
- Recovering：正在恢复的状态。节点启动后会短暂处于该状态，然后变成 Secondary。如果长期处于该状态，对应的场景是该节点的日志太就，无法找到合适的节点同步日志，此时一般需要清空数据后重新做全量同步。  
- Startup：刚启动时的状态。  
- Startup2：初始化全量同步的状态。对应的场景是新加入一个空节点（或者手动将某个节点的数据清空），该节点需要通过 Initial Sync 流程全量同步数据。  
- Arbiter：投票节点，不存储数据。  
此外，如果节点异常，会显示 Unknown、Down、Removed(Other) 状态。

另外 MongoDB 中的每个节点可以配置多种属性：   
- Votes：是否有投票权。所谓的“多数派提交”和“多数派选举”中的“多数”，指的就是包含有 votes 属性的节点。一个 MongoDB 副本集中最多只有7 个包含 votes 属性的节点。通过将 votes 属性设置为 0 ，可以加更多的从节点，因此这个属性一般会用在各大云厂商的“只读实例”产品中。  
- Priority：节点被选为主的优先级。riority 设置的数值越高，越会被选举为主。通过将 priority 设置为0，可以避免主节点切换到某些节点。  
- Hidden：是否将从节点隐藏起来不对外提供服务。设置为隐藏后，客户端驱动无法通过 isMaster/Hello 探测命令感知这个节点，因此无法向其发读请求，但是通过 rs.conf() 和 rs.Status() 命令还是能看到其配置。Hidden 节点一般作为备份节点。由于主节点不能被隐藏，因此官方规定 hidden=true 的节点需要 priority=0。  
- BuildIndexes：从节点是否建索引。如果设置为 false， 则不会同步创建索引。理论上可以节省索引占用的存储空间以及维护索引的 CPU 和内存消耗。但是如果从节点被选举为主，此时由于索引缺失可能会导致一些问题，因此官方规定 buildIndexes=false 的节点需要 priority=0，而且不能对已经加入副本集的节点进行动态变更。  
- Tags：为节点打标签，一般用户从节点的请求分流。比如副本集中有 4 个节点，其中 2 个节点硬件配置高，可用于在线服务，则设置这 2 个节点的 tag 为 {"usage":"online"}；另外 2 个节点硬件配置较低，只用户离线特征分析，则设置这 2 个节点的 tag 为 {"usage":"offline"}。用户程序可以根据自身请求特点设置readPreference 说明希望将请求发往 "online" 还是 "offline" 节点。  
- ArbiterOnly：轻量级从节点，不同步和存储数据，只负责选主投票。一般用于解决偶数副本数的场景。比如副本集中只有 2 个节点，必须全部存活才能选出主。加入一个 arbiter 节点之后，副本个数变为 3，可以容忍一个节点失效。  
- ●SlaveDelay：强行设置某个从节点距离主节点的主从延迟。比如设置 60 秒，则该从节点的最新日志同步时间比主节点要延迟 60 秒或以上。一般用于业务数据快速回滚（比如误删）和测试场景。  

通过状态区分和灵活的配置，MongoDB 能够更好地支持多样化的业务场景。

## 3.2 日志复制

## 3.3 选主协议
Raft 和 MongoRaft 都是 “强主”协议，所有的写操作都在主节点上完成，并复制到从节点。因此，如何快速安全的选出主节点非常关键。简单来说，主节点的选举由副本集中大多数节点（包括candidate节点自己）投赞成票而来，然而实际生产环境中还需要解决一些异常场景，包括：   
1. 触发选主的条件是什么？
2. 如何避免网络分区导致同时出现多个主节点？
3. 如何避免在配置变更时出现多个主节点？
4. 如何在出现投票冲突时快速达成一致？
5. 如何主动进行主节点切换？
6. 如何保证新主节点一定包含已提交的数据，即不会出现已提交的数据由于切主而丢失？

下面我们带着这些问题，分析一下 Raft 和 MongoRaft 的处理流程。其中配置变更时的选主安全性问题，我们单独在配置变更章节描述。

### 3.3.1 Raft 原理
#### 何时触发   
Leader 定期给 follower 发送心跳。如果 follower 节点在一段时间内（Election timeout）没有接收到心跳，则状态变为 candidate 并发起选主。   
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/c849c661-4c9a-4eef-ae0a-8bd31b6fbb69" width=300>

#### 选主流程   
Candidate 首先将 term 加 1，然后并发给副本集中的其他节点发 RequestVote 请求。Candidate 节点接下来可能会遇到 3 种场景：   
1. 副本集中大多数节点（包括 candidate 自己）投了赞成票，此时 candidate 成功变为 leader. 投票节点在每个 term 最多只会投出 1 张赞成票，而且为了防止出现已提交数据被回滚的情况，candidate 的日志必须足够新才能得到赞成票。   
2. 收到另外一个节点声明自己是 leader 的心跳信息。如果那个新 leader 的 term 大于等于自己当前的 term，则 candidate 变为 follower，否则忽略那个心跳。   
3. 没有收到大多数节点的赞成票，则 candidate 等待一段时间后 term 加1，重新发起选举。出现这种场景，可能是副本集中同时有多个 candidate，每个 candidate 都只得到了少数票。也有可能是副本集当前只有少数节点存活。   

对于上述第 3 种场景，raft 采用的解决方式是 candidate 等待随机一段时间后再重新发起选举，这样下次选举的冲突几率就非常低了。   
最初 raft 打算采用给 candidate 派优先级的方式来解决冲突（ranking system），优先级低的 candidate 如果发现有更高优先级的 candidate 存在，则出动退回到 follower 状态。这个方案看起来合理，但是实际测试中发现系统的可用性（无主时间）会收到较大影响，而且有很多极端场景导致的bug. 最终，还是选择了随机回退的方案。   
从 raft论文 给出的测试结果来看，随机回退能够有效避免选举冲突（split vote）的情况。   
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/40a79a7b-7ee7-4e09-82d8-44a4cdc41beb" width=400>
   
在上面的半张图中，150-150ms 的场景是没有任何随机性的，可能选主需要长达 10 秒才收敛。如果增加 5 ms 的随机性，即选主超时在 150-155ms 中的随机值，平均 287 ms 即收敛，可以说效果非常明显了。   
在下面的半张图中，raft 分析了将 election timeout 设置为多长更合适的问题。一般来说设置的短一点，follower 能很快发现无主并发起选择，降低系统无主的时间，比如实验中设置 12-24ms 的 election timeout, 平均只需要 35ms 就能选出新主。   
但是设置的太短也有问题，如果出现一些网络延迟抖动，可能导致一些不必要的选主和切主。比如 3 副本分别在中国、北美和南美，网络 RTT 就在百 ms 级别，而且网络不稳定，如果设置 election timeout 为 200 ms, 可能会导致选主非常频繁。**因此，election timeout 的设置要依据网络距离，网络质量等因素进行综合评估。**   

#### 选主成功后的流程
如果 candidate 成功变为 leader，则立刻向其他节点发送心跳昭告自己的状态，并避免新的选举发生。

### 3.3.2 MongoRaft 原理
#### 何时触发
mongo 的选主支持主动和被动 2 种触发方式。
主动触发的方法有：   
- 主节点主动 stepDown。在主节点上主动执行 replsetStepDown 命令，主节点会马上转为 secondary, 并很快选举出新主节点。相比重启主节点来触发选主，replsetStepDown 方式触发选主的时间更短，从节点不需要等待 election timeout （默认 10 秒）就发起选主。   
- Priority takeover。如果某个节点发现自己配置了比主节点更高的 priority，则会在等待一段时间后（参考 getPriorityTakeoverDelay）发起选举。   

被动触发一般对应节点不通的场景：   
- 主节点一段时间内（election timeout, 默认 10 秒）感知不到大多数节点的存在，则主动 stepDown。  
- 从节点一段时间内（election timeout, 默认 10 秒）感知不到主节点的存在，则发起选举。  

Mongo 也使用了心跳机制来感知各个节点的状态，但是与 raft 不同的是，Mongo 中的任意 2 个节点都能相互发心跳请求：   

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/607a6fd1-6969-4a41-a042-c1f2f0a8a9cf" width=500>

由于任意 2 个节点之间都能互发心跳，对于 N 个节点的副本集，平均每个心跳周期内，副本集内的总心跳请求有 N(N-1) 个，如果节点太多会出现爆发式增长。这也是 MongoDB 限制一个副本集最多 50 个节点的原因之一。   
这种心跳机制的好处是，副本集中每个节点都能知道全局的节点状态信息，因为心跳信息中包含了节点的 opTime 同步进度，replsetConfig 版本，主节点的状态和 term 等信息。    
基于上述机制，副本集中的从节点可以根据一定的规则选择合适的同步源节点，并形成链式复制结构（生成无环的 spanning tree）。   
另外，在 MongoDB 的复制模型中，拉取 oplog 的请求和更新oplog 复制位置的请求会携带包含节点状态的元数据。   
以下图为例，副本集中有 5 个节点，在某个时刻主节点 A 和 C, D, E 网络不通，但是 B 和所有节点都能正常通信：   

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/f5450ee0-bcec-40ce-a376-cfad9a2c4bd4" width=600>

对于左侧 Raft 来说，C, D, E 在一段时间内接收不到主 A 的心跳，会发起选主。   
对于右侧的 MongoRaft 来说，C, D, E 可以从 B 节点同步，链式复制结构会让 A 通过 B 节点感知到 C、D、E的状态，而不用重新发起选主。   
不过需要注意的是，如果节点 B 是 arbiter 或者数据非常落后，则不会形成上述链式复制结构。   

#### 选主流程
选主流程分为 2 步：   
1. Dry-run election, 即试探性发起选举。其目的在于试探集群中有多少节点会支持自己，增加后续真正选举的成功率。发起 dry-run election 时不会增加自己的 term，所以不会造成 term 无意义的递增，而且也不会导致当前的 Primary 节点 stepDown.   
2. Real election，candidate将 term 加 1，然后真正发起选举。首先 candidate 会投票给自己，然后并发给集群中有投票权的节点发起投票请求。如果获得了大多数赞成票，则选举成功。   

从 voter 的视角来看，它在收到 candidate 发过来的 requestVotes 命令时，先判断 term 是否比自己的新，并更新自己的 term. 然后判断自己是否应该投赞成票，如果满足以下条件，会投反对票：  
- Candidate 的 term 更低。   
- 配置不匹配，replSetName 不匹配。   
- Candidate 的数据更旧（lastAppliedOptime更小）。   
- 对于这个 term，voter 已经投过一次票了（当然 dry-run 流程的不算数）。   
- Voter 是一个 arbiter, 而且它能感知到当前存活了另一个主，并且这个主的 priority 不比 candidate 低。这个策略主要是应对 Primary-Secondary-Arbiter 架构下，primary 和 secondary 不能通信，arbiter 能够和它们都正常通信的场景。如果 arbiter 没有这样的投票策略，可能同时会出现 2 个主。   

一旦节点给自己或者其他节点投票，则会将 “lastVote” 信息持久化到本地的 local.replset.election 表中，避免节点重启之后这些信息丢失，导致给同一个 term 多次投票的情况。   

#### 如何保证选主流程的安全
一个节点只给一个 term 投 一次票的机制，避免了一个 term 出现多个主节点的情况，但在某些时刻，集群中可能出现 2 个主的情况，分属于不同的 term。    
举例如下：   
<TODO 选主流程安全图 1>   

(a). 所有节点运行在 term 1, 其中S1 为主节点。    
(b). S1和S5 出现网络隔离，S5 发起选举并获取 S3、S4、S5的投票成为了新主。S1、S2 运行在 term 1, S3、S4、S5运行在 term 2。    
(c). S1 和 S5 都能接收客户端的写请求，S5 的写请求能提交（到大多数节点）。S1 的写请求只能复制到 S1 和 S2，其他节点由于网络不通，因此会卡住不能提交。    
(d). S1 的日志复制到 S3、S4、S5, 但是term 太低并拒绝。    

对于 Raft 来说，S1 推送给 S3、S4、S5 的复制请求会由于自身 term 太低被拒绝。    
而对于 MongoRaft 来说，由于采用了从节点拉日志的方式，情况要更复杂一些。在上述例子中，S3 和 S4 的日志复制取决为当时的同步源节点是否切换为 S5，如果切换为 S5 则压根不会从 S1 节点复制日志。如果同步源还是 S1 ，则会在应用日志后，通过 updatePosition 命令给 S1 反馈日志同步情况，该命令中会携带 S3/S4 自身的 term 为 2。 S1 在收到这个命令后，明白自身的 term 太低，主动 stepDown，并不会将该写请求置为提交。   
MongoDB 论文中列举了不一样的例子：   
<TODO MongoRaft 中的图>    

(a). A、B运行在 term 2, A 作为主节点提交了日志 “2”；C、D、E 运行在 term 3， E 作为主节点提交了日志 “3”.   
(b). Raft 协议：A的日志只能复制到节点B，C、D、E 节点由于 term 更高会明确拒绝。   
(c). MongoRaft 协议：A 的日志可以复制到 C 和 D.   
(d). MongoRaft 协议：C 和 D 在updatePosition 反馈时表名自己是 term 3，A 收到后主动 stepDown，不会提交日志 “2”。   
(e). MongoRaft 协议：E 节点的日志“3”复制到所有节点，并 overwrite A节点的日志“2”。   
整体来看，虽然由于复制模型导致处理过程不一样，但是 MongoRaft 和 Raft 殊途同归。   

引入 term 机制后确实避免了同时出现多主并同时提交日志的问题。但是也引入了另外一个问题：主节点是否能提交之前 term （older term）的日志？   
对于 Raft 和 MongoRaft 来说，答案都是否定的。   
首先引用 Raft 论文中的一个例子，看看提交主节点如果提交之前 term 的日志会有什么问题：   
<TODO new term 和 old term 的图>   

(a). S1 是主节点，并将最新的日志 "2" 同步到了 S1 和 S2，还没有提交。    
(b). S1 挂了，S5 被 S3、S4、S5 选举为新主，运行在 term 3，并写入了日志 “3” 但没有复制到其他节点。    
(c). S5 挂，S1 重启并成为新主。然后继续将之前的日志 “2” 复制到 S3, 此时已经复制到了大多数节点（已经复制到了S1、S2、S3），但还没有提交。    
(d). S1 没有提交日志 “2” 就挂掉，则 S5 可能重新被选为主，并在选主之后会将之前已经复制到大多数的日志“2” 抹掉（overwrite）。   
(e). S1 提交了当前 term 的日志“4” 才挂掉，则 S5 不可能被选为主。日志 “2”在日志“4”之前，才会保持提交状态。  

>需要特别说明的是，为什么提交了日志 “4”， S5 就不会被选举为新主，而之前“提交”了日志 “2”， S5 却能被选举为新主呢？
>Raft 选举时，voter 给 candidate 是否投票，有一项主要的依据就是比较日志的新旧：如果 voter 的日志更新，就不会给 candidate 投票。而比较日志的新旧，首先就是要比较日志中的 term 大小。
在上述例子中，日志“2” 的 term小于日志“3” 的 term，日志 “3” 的 term 小于日志“4” 的 term。

从上述场景(d) 中可以看到，即使older term 的日志复制到了大多数节点，还是可能被抹掉。因此，Raft 中的主节点不会通过计算日志是否复制到了大多数节点来提交日志，而是**通过提交当前 term 的日志来间接提交之前 term 的日志**（场景(e))。   
Raft 论文中也提到，采用上述“一刀切”的机制还是方便协议的理解落地，降低复杂性。理论上来说，如果在上述步骤 (c) S1 挂掉之前，日志 “2” 复制到了所有节点（并 overwrite 了 S3 的日志“3”），其实也能肯定日志“2” 的提交状态。   

MongoDB 也采用了一样的机制，如果从节点反馈的 updatePosition 中的 term 较低，主节点不会真正提交这条日志。只有收到的反馈中 term 和主节点当前的 term 相同，才会真正提交这条日志。在某一条日志被提交之后，比其更早（opTime 更小、term 更小）的日志也间接提交了。   

**这也是为啥 MongoDB 在选举新主节点之后，会马上生成一条当前 term 的 oplog 日志，其实就是为了提交更早 term 的日志。**   

#### 选主成功后的流程
新主节点在选举成功之后会进入如下流程：   
1. 停止当前的同步逻辑，并将自己选举成功的消息通过心跳告知其他节点。   
2. 检查自己是否需要 catch-up. 比如副本集中有 5 个节点，数据从新到旧的排序为 A>B>C>D>E，B得到了 BCDE 的投票成为新主。A 节点上存在一些更新的日志，虽然没有提交，但是 B 节点也会同步过去。具体实现流程为步骤1 中的心跳响应中包含了各个节点的 lastAppliedOpTime 信息，如果有节点比自己新，则这个新主节点就会进入 catch-up 阶段尽可能多同步一些日志。在进入 catch-up 节点之前，新主节点会启动一个定时器，防止catch-up 时间不可控，集群长期无主影响可用性。如果 catch-up 超时也没有关系，因为这只是一个尽力而为的操作。   
3. Catch-up 不论成功与否，接下来会进入 drain-mode. 新主节点将拉过来的日志进行回放（apply）。   
4. 新主节点写一条 “new primary” 的 oplog，方便提交之前 term 的日志。   
5. 新主节点删除上述临时表、终止残留的事务。此时选主操作才真正完成，新主节点可以对外提供写服务。   

从上述流程可以看出，catch-up 阶段时选主成功后 MongoRaft 和 Raft 最大的区别。MongoRaft 通过这个机制可以尽量保留已经写入到主节点但是还没有提交（到大多数节点）的数据。主要是因为MongoDB 支持非 majority的写入方式。比如客户端为了性能考虑，可以在只写主成功后即返回。原则上来说，这些数据是可能被回滚的，MongoDB 也不保证这种写入方式的持久性。但是，能 MongoDB 在设计上尽量避免发生回滚。

### 3.3.3 小结
纵观 Raft 和 MongoRaft 的选主流程，在心跳探活、term、大多数选举等机制上大致相同。但是 MongoRaft 相比 Raft，还是在不少方面做了改进，包括：   
- 探活机制方面，MongoRaft 任意 2 个节点之间都有心跳，容错性更高。另外，MongoRaft 支持灵活的链式复制架构生成 spanning tree 并传递节点状态信息。使得集群对网络的容错性也更高，避免发生不必要的选举。
- 选主流程上，MongoRaft 引入了 dry-run 机制，提升了真正选举时的成功率，避免不必要的term 递增以及由此造成的主节点 stepDown。
- 选主成功后，MongoRaft 引入了 catch-up 机制，尽可能地保留已经写到主节点但是还没有提交（到大多数节点）的数据，增强了数据持久性，减少回滚操作。


## 3.4 配置变更
在副本集运行过程中会遇到配置变更需求，比如新增加一个节点提升读能力，或者删除一个机器故障的节点等。    
一种比较原始的方法，是将配置写在配置文件中。如果需要修改配置，则停掉所有节点，统一修改配置之后再重启所有节点。但是这种简单粗暴的方法并不适用于线上系统，因为很大程度上影响了系统的可用性，并增加了误操作风险。    
因此，非常有必要支持不停服变更配置。    
下面先从 [Raft 论文](https://raft.github.io/raft.pdf)中描述的算法入手，了解配置变更的问题以及解决方案。然后分析 MongoRaft 的实现方法，以及相对 Raft 有哪些改进。

### 4.4.1 Raft 原理
为了做到不停服，就需要解决变更配置期间系统运行的安全性问题。我们知道新配置的同步是需要时间的，在这段时间内集群中新、老配置共存，可能引发同时存在多个主节点的问题。论文中列举了一个例子如下：    
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/b6dd40f6-8ce7-4798-bf48-5f820a3a4142" width=400>

起始时刻，集群中有 Server 1,2,3 共 3个节点按照 C(old) 配置正常运行，后来加入了 2 个节点 Server 4 和 Server 5。在中间某一时刻，Server 1, 2 还在使用 3 节点的旧配置，但是 Server 3,4,5 已经使用了 5 节点的新配置。如果 Server 1,2 与 Server 3,4,5 出现了网络隔离，则 Server 1,2 之间会选出一个主节点（满足总节点数为 3 的选举条件），Server 3,4,5 之间也会选出一个主节点（满足总节点数为 5 的选举条件）。 2 个主节点都能接收并提交写请求。

为了解决上述问题，Raft 采用 2 阶段流程来实现不停服配置变更，具体流程为：       
1. 生成 C(old, new) 日志，并提交到 C(old) 的大多数节点和 C(new) 的大多数节点。
2. 生成  C(new) 日志并提交到集群的大多数节点，如果有节点发现自己不在新配置中，则主动退出。     

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/5212f6fd-350e-4d41-9a4b-946ee77469f5" width=400>
  
需要说明的是，C(old, new) 不只是简单的将 C(old) 和 C(new) 的节点做并集。C(old, new) 的真正的含义是：每项决议（选主和日志提交）都需要 C(old) 的大多数节点通过**而且** C(new) 的大多数节点通过。     
通过这种方式，避免了集群在同一时刻同时存在 C(old) 和 C(new) 并且各自独立进行决议的问题。但是又引入了 3 个新问题：
1. C(old) 和 C(old, new) 能否共存？    
如果 C(old,new) 还没有完成提交就出现了主节点宕机或者网络分区，此时可能会选举新主。不妨假设假设新主节点在 C(old) 配置下，则其需要获得 C(old) 中大多数节点的赞成票；假设新主节点在 C(old, new) 配置下，则其同时需要 C(old) 和 C(new) 中大多数节点的赞成票。**也就是说，无论如何都需要收到 C(old) 中大多数节点的赞成票**。由于C(old) 节点中大多数节点的赞成票只会投给一个节点（Election Safety），因此不会再同一时刻出现 2 个主节点。    
至于新主节点可能运行在  C(old) 配置下，也有可能运行在 C(old, new) 配置下，具体取决于故障之前 C(old, new) 的同步情况。    
2. C(old, new) 是否为稳定状态?      
如果 C(old, new) 状态被提交，说明 C(old, new) 配置已经同时提交到了 C(old) 和 C(new) 中的大多数节点。如果此时发生主节点宕机或者网络分区，新主节点肯定会运行在 C(old, new) 配置下，其选举要同时获得 C(old) 大多数节点的赞成票以及 C(new) 中大多数节点的赞成票。因此，不会出现 2 主节点。   
3. C(old, new) 到 C(new) 能否平滑过渡？       
C(old, new) 被提交之后，主节点接着会提交 C(new)。如果在提交 C(new) 的过程中出现了主节点宕机或者网络分区导致重新选主。则新主节点要么运行在 C(old, new) 下，要么运行在 C(old) 下，绝不可能运行在 C(old) 下，因为前面 C(old, new) 的成功提交已经保证了即使还有节点运行在 C(old) 下，也构不成大多数。      
不妨假设新主节点运行在 C(old, new) 下，则其需要同时获得 C(old) 和 C(new) 中大多数节点的赞成票；如果新主节点运行在 C(new) 下，则其需要获得 C(new) 中大多数节点的赞成票。也就是说不论怎么选举，新主节点都需要 C(new) 中大多数节点的赞成 。因此，不会出现 2 个主节点。      

除了新旧配置的安全过渡之外，Raft 论文中还描述了一些工程实践中常见的异常场景：       
- **新加入节点的延迟过大问题**。新加入的节点需要花较长的时间进行数据同步（catch-up），一般是全量加日志增量的方式。由于 Raft 中日志顺序提交的特性，配置变更日志和数据变更日志糅合在一起，会导致配置变更日志需要较长的时间才复制到新加节点上，整个配置变更的时间也随之变长。为了解决这个问题，Raft 建议按照 non-voting 模式添加新节点，这种模式的节点不会算在 majority 范围，因此不会阻塞配置变更的提交。     
- **主节点不在 C(new) 新配置中**。如果主节点发现自己不在 C(new) 中，就立刻 step down 并退出集群，则 C(new) 日志无法在集群中提交。这种情况下，意味着已经要被剔除的节点还要承担一段时间的集群管理任务。Raft 建议的做法是该主节点要等到 C(new) 在集群中提交之后再退出，当然这里提交时的大多数节点是不包含它自己的。
- **已删除的节点发起选主请求**。第一次看到这问题比较诧异，因为论文中明确描述了 C(new) 提交之后，不在 C(new) 中的节点主动停服并退出集群，为啥还有已删除节点发起选举的问题呢？后来想了一下，个人认为这里说的应该是配置提交过程中因为各种原因没有收到新配置的节点。这些节点因为已经被剔除，无法收到主节点的心跳，所以会尝试通过RequestVote RPC 选主，导致主节点降为 follower 状态。然后集群重新选主，选出的新主又不给这些已删除 的节点发心跳，然后这些已删除的节点又要闹着选主。Raft 建议的做法是从节点如果在 election timeout 内成功收到过主节点的心跳，或者主节点在 election timeout 内成功收到过大多数节点的心跳，则认为主节点正常。如果这段时间有节点闹着选主，一概拒绝之。

Raft 的配置变更流程整体来看比较完善，但是实际工程实践中还有一些场景有待优化。个人认为有 2 点：     
1. 没有充分说明主从延迟很大时的效率问题。     
Raft 将配置和数据变更都放在日志中提交，这样导致主从延迟大时，配置变更操作很可能卡住。比如线上 1主 2 从的副本集，2 个从节点延迟 1 个小时，我希望将 1 个从节点剔除后换个高性能节点，那这个变更操作可能会卡 1 个小时。显然是无法接受的。     
可能有人会想到，可以参考加节点的方法，先将 2 个从节点变成 non-voting 模式，不算在 majority，配置变更就能很快提交了。然而问题是，调整 non-voting 本身就是配置变更操作，这项操作首先就会卡住。
2. 对主节点强依赖。
Raft 论文中描述的配置变更算法都依赖主节点执行，然而实际场景中我们可能遇到无主节点的情况。比如 3 节点副本集，有 2 个节点的机器永久性损坏了，不可能自己选出主节点，此时该如何恢复呢？      
一种简单粗暴的方法，就是将仅剩的节点停掉，然后改配置，再作为单节点的方式重启。     

### 4.4.2 MongoRaft 原理
MongoRaft 的实现原理可以参考作者发布的[论文](https://drops.dagstuhl.de/opus/volltexte/2022/15801/pdf/LIPIcs-OPODIS-2021-26.pdf)，MongoDB 4.4 版本的代码实现可以参考源码中的 [README.md](https://github.com/mongodb/mongo/blob/r4.4.24/src/mongo/db/repl/README.md)。结合论文和代码实现，我认为 MongoRaft 和 Raft 在配置变更流程上有 3 点重大区别：   
1. **Logless**. 结合前面的分析我们看到 Raft 的配置变更流程还是要依赖日志同步，日志同步的快慢或多或少会对配置流程的时长会有影响。而 MongoRaft 采用了“无”日志的方式（也不是整个过程完全没日志，所以要加个引号），使用基于心跳的 Gossip-like 协议进行配置变更同步。在流程上将配置变更和数据同步分开，再保证数据安全的前提下尽量快速进行变更。    
2. **没有照搬 Raft 的 2阶段算法进行配置的安全过渡**。MongoRaft 使用了更加简单巧妙的方式。具体来说，新配置和旧配置必须保证 Quorum 节点有重叠，每次只能有一个 voting节点加入或者删除（对于 non-voting 成员，由于它们不属于 majority(quorum) 的计算范围，因此没有这项限制）。通过这个限制，可以使得协议实现更加简单，但是如果要添加或者删除很多节点，则可能需要发起多次配置。我们可以简单论证一下这种方法的安全性：当前配置C1 和新配置 C2 如果要同时选举产生不同的主节点，则必须通过获得 C1 的主节点需要获得 C1 中大多数节点的同意，C2 的主节点也需要获得 C2 中大多数节点的同意，但是现在 C1 中大多数节点和 C2 中大多数节点必定是有重叠的（QuorumOverlap），这些重叠的节点不会在同一个选举周期内给 2 个不一样的节点投赞成票。因此，通过反证法能够证明不可能同一时刻在 2 个配置中出现 2 个不一样的主节点。
3. **支持 unsafe(force) 模式**。真实业务场景中可能会出现节点损坏较多无法选主的情况，MongoRaft 支持在非主节点发起强制配置变更。Unsafe 模式会跳过很多安全性检查，有数据回滚、丢失的风险。因此，这种模式一般用来应急使用，而不是常规手段。

下面以 MongoDB 4.4 版本的实现进行详细分析。由于 unsafe 模式同 safe 相比主要是跳过了一些检查，因此这里只分析 safe 模式。

#### 配置构成
MongoDB 的配置方法和配置选项可以直接参考[官方文档](https://www.mongodb.com/docs/v4.4/reference/method/rs.reconfig/)，这里不再赘述。

#### 核心流程
配置信息持久化存储在每个 mongod 节点自己的 local.local.system.replset 表中。我们知道 local 库是每个 mongod 本地私有的，不会通过 oplog 同步到其他节点。因此，配置信息不是通过 oplog 同步，而是使用心跳进行同步。    
为了保证变更流程的安全性，除了上述每次添加和删除的节点个数限制之外，执行 reconfig 的主节点还要做 2 项检查（假设当前的配置是 C1,上一个配置是 C0, 即将要变更的配置是 C2）：    
1. 当前配置 C1，已经被复制到了副本集的大多数 voting 成员。
2. 上一个配置 C0 已经提交的数据（复制到大多数 C0 的 voting 成员），在当前配置C1 中也是提交状态，才能进行下一步的状态变更。

其中第 1 项检查保证了 C0 不再有形成大多数的机会。否则在 C1 到 C2 的变更过程中，C0 配置如果也选举了一个主节点，则整个副本集中将同时有  2 个主节点接受写入。    
第 2 项检查保证了已经提交的数据不会因为配置变更而回滚丢失，为了方便理解，参考下面的示意图：     

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/9b10f846-0cf5-480a-9801-c8493846e9fc" width=700>

    
图中所有节点都是 voting 节点，最开始有一条数据在 A, C,E 上提交。节点 E 被删除后，副本集中只有 4 个节点，数据存在于 A 和 C 中，此时不满足大多数条件，但是数据还没有回滚丢失的风险。      
下一步，在没有等待数据同步到 B 时就又进行了一次配置变更，这次增加了一个节点 F。这时问题来了，如果 A 和 C 同时挂掉，会选举 B 或者 D 成为主节点继续接受写入，而 A 和 C 中的数据丢失了。即使 A 和C 重启了恢复正常，也会成为从节点，并将最近提交的数据回滚掉。    
可以看到，如果在第 2 次变更之前，先等待数据同步到 B ，使得数据变更满足大多数节点的提交状态，才能安全的进行下一步配置变更，示意图如下：      
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/1769cb27-1435-461d-851c-b18873e10ff0" width=900>
    
检查完成，满足安全配置变更条件之后，主节点就执行真正的配置变更流程了，示意图如下：     
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/cbb17664-6e75-407e-afba-be7e512fac95" width=900>
    
主要流程为：    
1. 主节点确保当前配置同步到了大多数 voting 节点，awaitConfigCommitment(currentConfig).     
2. 主节点检查新配置是否合法，以及新配置中节点的状态情况，configValidation & checkQuorumForReconfig.   
3. 主节点将新配置持久化到本地的 local 库中，并更新内存中维护的配置信息。storeLocalConfigDocument & setCurrentRSConfig.   
4. 主节点等待配置同步到大多数节点（提交成功），这里同步是采用心跳的方式，因此最终也是由心跳处理流程唤醒。   
5. 2 个从节点给主节点发（周期性）心跳请求，心跳请求中会携带从节点自己的配置版本号。主节点发现自己的配置版本更高，因此会在心跳响应中塞入新配置，传给从节点。   
6. 2 个从节点接受到更高版本的配置信息，应用到自身节点。即持久化到本地的 local 库，并更新内存中维护的配置信息。storeLocalConfigDocument & setCurrentRSConfig.   
7. 主节点（周期性）给从节点发送心跳请求，发现 2 个从节点都使用了最新配置。认为新配置已经复制到了大多数 voting 节点，已经提交。此时可以给客户端返回 success.    

Mongod 节点内部维护了一个状态机，确保同一时刻主节点上最多只有 1 个 reconfig 操作处于执行中，避免并发操作相互干扰。   
如果在变更流程中出现了节点故障，或者新配置一直没有提交到大多数 voting 节点，则 reconfig 命令可能会失败或者超时。然而在后台新配置可能还是会通过 Gossip-like 协议完成提交。所以客户端在重试之前可以先做一些检查。   

整体变更流程中，心跳发挥了非常重要的作用，包括前期的配置检查 checkQuorumForReconfig, 新配置同步，以及同步情况检查。[心跳请求](https://github.com/mongodb/mongo/blob/r4.4.13/src/mongo/db/repl/repl_set_heartbeat_args_v1.h#L48)和[心跳响应](https://github.com/mongodb/mongo/blob/r4.4.13/src/mongo/db/repl/repl_set_heartbeat_response.h#L50)包含的信息如下：   

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/a322ba73-5dfa-43be-9b5e-1d015c65106c" width=400>

   
副本集内任意2 个节点之间都会有周期性心跳（默认 2 秒），每个节点也可以在一些流程中主动触发心跳，比如节点拓扑发生改变，或者上述变更流程中的 checkQuorumForReconfig 逻辑等。心跳除了探活之外，还会携带 term，configVersion 等信息。如果节点在收到心跳请求时，发现对方的配置版本比自己低，则会在心跳响应中附带上自己完整的配置信息。    

#### 测试分析
我们可以通过下面的测试，验证一下 MongoDB 在主从延迟很大的时候能否快速完成配置变更。   
测试环境为：4.4.13 副本集，3 个 voting 节点，为了方便测试观察，心跳周期设置为 10s（默认 2s）, 选主超时配置为 60s（默认 10s）, 2 个 从节点 slaveDelay 10min（默认没有 slaveDelay, 设置为 hidden 是为了防止主节点切换）. 后台 10 秒 1 次写请求。   
配置变更操作为将一个从节点的 slaveDelay 从 600s 改成 601s.   

首先我们验证正常情况下的配置变更耗时。在执行变更前当前配置已经运行了很长时间，处于提交状态。而且没有切主及 term 变更。   
测试得到的总耗时为 10.902s, 通过在代码中添加日志，看看具体耗时的分布情况：   
1. 第1阶段，确认当前配置复制到了大多数 voting 节点，并且当前 term 的第一条oplog 同步到了大多数，耗时忽略不计（小于 1ms）。   
2. 第 2 阶段，配置检查+大多数节点状态检查+本地配置应用，耗时 811ms。   
3. 第 3 阶段，确认新配置同步到了大多数 voting 节点，耗时 10.091s。   

可见，正常情况下，配置变更流程的耗时主要集中在心跳检查阶段。由于 MongoDB 默认的心跳周期是 2s, 所以正常情况下 2s 左右就能完成配置变更，即使主从延迟有 10分钟也没关系。

再来看看异常情况，主节点重启并继续成为主(term++), 由于 slaveDelay 很大，会在第一阶段阻塞很久。总耗时 10min.   
通过加日志发现，这里的耗时基本都在第 1 阶段，等待当前 term 的第一条日志复制到大多数节点。由于我们测试环境的 slaveDelay 配置为 10 分钟，因此这里也卡了 10 分钟。通过代码我们可以看到第 1 阶段确认 oplog 最小提交时间的判断条件为 std::max(_lastCommittedInPrevConfig, _firstOpTimeOfMyTerm); 

另外，通过测试发现， reconfig 流程也会生成 oplog，这也是为什么要对 logless 的“无”日志变更加上引号的原因：   

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/31511f6f-671b-46f1-abcd-9c06275bcecb" width=700>

 
同样，出现了选主及 term 变更，也会生成一条 oplog, 也就是上述 _firstOpTimeOfMyTerm 的依据。   

#### 小结
1. Raft 协议通过动态变更算法保证了配置变更流程中的可用性，并通过 2 阶段的方式保证安全。   
2. MongoRaft 在 Raft 基础上，借助心跳机制实现配置变更和数据复制分离，能够很大程度上缓解主从延迟大带来的配置变更耗时长的问题。并通过 QuorumCheck 的机制在保证安全性的同时简化了配置变更算法。   
3. MongoRaft 提供了 unsafe(force) 模式，能够在非主节点上实现强制变更，能够在极端情况下快速完成服务恢复。   


## 3.5 一致性讨论

# 4. 总结

# 5. 参考文档
1. Design and Analysis of a Logless Dynamic Reconfiguration Protocol， https://drops.dagstuhl.de/opus/volltexte/2022/15801/pdf/LIPIcs-OPODIS-2021-26.pdf
2. In Search of an Understandable Consensus Algorithm (Extended Version)，https://raft.github.io/raft.pdf
3. https://raft.github.io/
4. https://github.com/mongodb/mongo/blob/r4.4.24/src/mongo/db/repl/README.md
5. 共识协议的技术变迁，https://mp.weixin.qq.com/s/UY9TPMcuf0O7xS0kuXTcVw


