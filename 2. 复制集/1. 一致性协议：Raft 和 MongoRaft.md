# 1. 导语
本文首先从原生 Raft 入手，从 Raft 论文简要了解其设计思想和系统流程。然后重点介绍 MongoDB 的一致性协议，并分析相比原生 Raft 所作的改动以及会带来哪些效果。

# 2. 初识 Raft

# 3. 初识 MongoRaft

# 4. 深入分析 MongoRaft
## 4.1 节点状态

## 4.2 选主协议

## 4.3 日志复制

## 4.4 配置变更
在副本集运行过程中会遇到配置变更需求，比如新增加一个节点提升读能力，或者删除一个机器故障的节点等。    
一种比较原始的方法，是将配置写在配置文件中。如果需要修改配置，则停掉所有节点，统一修改配置之后再重启所有节点。但是这种简单粗暴的方法并不适用于线上系统，因为很大程度上影响了系统的可用性，并增加了误操作风险。    
因此，非常有必要支持不停服变更配置。    
下面先从 [Raft 论文](https://raft.github.io/raft.pdf)中描述的算法入手，了解配置变更的问题以及解决方案。然后分析 MongoRaft 的实现方法，以及相对 Raft 有哪些改进。

### 4.4.1 Raft 原理
为了做到不停服，就需要解决变更配置期间系统运行的安全性问题。我们知道新配置的同步是需要时间的，在这段时间内集群中新、老配置共存，可能引发同时存在多个主节点的问题。论文中列举了一个例子如下：    
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/b6dd40f6-8ce7-4798-bf48-5f820a3a4142" width=400>

起始时刻，集群中有 Server 1,2,3 共 3个节点按照 C(old) 配置正常运行，后来加入了 2 个节点 Server 4 和 Server 5。在中间某一时刻，Server 1, 2 还在使用 3 节点的旧配置，但是 Server 3,4,5 已经使用了 5 节点的新配置。如果 Server 1,2 与 Server 3,4,5 出现了网络隔离，则 Server 1,2 之间会选出一个主节点（满足总节点数为 3 的选举条件），Server 3,4,5 之间也会选出一个主节点（满足总节点数为 5 的选举条件）。 2 个主节点都能接收并提交写请求。

为了解决上述问题，Raft 采用 2 阶段流程来实现不停服配置变更，具体流程为：       
1. 生成 C(old, new) 日志，并提交到 C(old) 的大多数节点和 C(new) 的大多数节点。
2. 生成  C(new) 日志并提交到集群的大多数节点，如果有节点发现自己不在新配置中，则主动退出。     

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/5212f6fd-350e-4d41-9a4b-946ee77469f5" width=400>
  
需要说明的是，C(old, new) 不只是简单的将 C(old) 和 C(new) 的节点做并集。C(old, new) 的真正的含义是：每项决议（选主和日志提交）都需要 C(old) 的大多数节点通过**而且** C(new) 的大多数节点通过。     
通过这种方式，避免了集群在同一时刻同时存在 C(old) 和 C(new) 并且各自独立进行决议的问题。但是又引入了 3 个新问题：
1. C(old) 和 C(old, new) 能否共存？    
如果 C(old,new) 还没有完成提交就出现了主节点宕机或者网络分区，此时可能会选举新主。不妨假设假设新主节点在 C(old) 配置下，则其需要获得 C(old) 中大多数节点的赞成票；假设新主节点在 C(old, new) 配置下，则其同时需要 C(old) 和 C(new) 中大多数节点的赞成票。**也就是说，无论如何都需要收到 C(old) 中大多数节点的赞成票**。由于C(old) 节点中大多数节点的赞成票只会投给一个节点（Election Safety），因此不会再同一时刻出现 2 个主节点。    
至于新主节点可能运行在  C(old) 配置下，也有可能运行在 C(old, new) 配置下，具体取决于故障之前 C(old, new) 的同步情况。    
2. C(old, new) 是否为稳定状态?      
如果 C(old, new) 状态被提交，说明 C(old, new) 配置已经同时提交到了 C(old) 和 C(new) 中的大多数节点。如果此时发生主节点宕机或者网络分区，新主节点肯定会运行在 C(old, new) 配置下，其选举要同时获得 C(old) 大多数节点的赞成票以及 C(new) 中大多数节点的赞成票。因此，不会出现 2 主节点。   
3. C(old, new) 到 C(new) 能否平滑过渡？       
C(old, new) 被提交之后，主节点接着会提交 C(new)。如果在提交 C(new) 的过程中出现了主节点宕机或者网络分区导致重新选主。则新主节点要么运行在 C(old, new) 下，要么运行在 C(old) 下，绝不可能运行在 C(old) 下，因为前面 C(old, new) 的成功提交已经保证了即使还有节点运行在 C(old) 下，也构不成大多数。      
不妨假设新主节点运行在 C(old, new) 下，则其需要同时获得 C(old) 和 C(new) 中大多数节点的赞成票；如果新主节点运行在 C(new) 下，则其需要获得 C(new) 中大多数节点的赞成票。也就是说不论怎么选举，新主节点都需要 C(new) 中大多数节点的赞成 。因此，不会出现 2 个主节点。      

除了新旧配置的安全过渡之外，Raft 论文中还描述了一些工程实践中常见的异常场景：       
- **新加入节点的延迟过大问题**。新加入的节点需要花较长的时间进行数据同步（catch-up），一般是全量加日志增量的方式。由于 Raft 中日志顺序提交的特性，配置变更日志和数据变更日志糅合在一起，会导致配置变更日志需要较长的时间才复制到新加节点上，整个配置变更的时间也随之变长。为了解决这个问题，Raft 建议按照 non-voting 模式添加新节点，这种模式的节点不会算在 majority 范围，因此不会阻塞配置变更的提交。     
- **主节点不在 C(new) 新配置中**。如果主节点发现自己不在 C(new) 中，就立刻 step down 并退出集群，则 C(new) 日志无法在集群中提交。这种情况下，意味着已经要被剔除的节点还要承担一段时间的集群管理任务。Raft 建议的做法是该主节点要等到 C(new) 在集群中提交之后再退出，当然这里提交时的大多数节点是不包含它自己的。
- **已删除的节点发起选主请求**。第一次看到这问题比较诧异，因为论文中明确描述了 C(new) 提交之后，不在 C(new) 中的节点主动停服并退出集群，为啥还有已删除节点发起选举的问题呢？后来想了一下，个人认为这里说的应该是配置提交过程中因为各种原因没有收到新配置的节点。这些节点因为已经被剔除，无法收到主节点的心跳，所以会尝试通过RequestVote RPC 选主，导致主节点降为 follower 状态。然后集群重新选主，选出的新主又不给这些已删除 的节点发心跳，然后这些已删除的节点又要闹着选主。Raft 建议的做法是从节点如果在 election timeout 内成功收到过主节点的心跳，或者主节点在 election timeout 内成功收到过大多数节点的心跳，则认为主节点正常。如果这段时间有节点闹着选主，一概拒绝之。

Raft 的配置变更流程整体来看比较完善，但是实际工程实践中还有一些场景有待优化。个人认为有 2 点：     
1. 没有充分说明主从延迟很大时的效率问题。     
Raft 将配置和数据变更都放在日志中提交，这样导致主从延迟大时，配置变更操作很可能卡住。比如线上 1主 2 从的副本集，2 个从节点延迟 1 个小时，我希望将 1 个从节点剔除后换个高性能节点，那这个变更操作可能会卡 1 个小时。显然是无法接受的。     
可能有人会想到，可以参考加节点的方法，先将 2 个从节点变成 non-voting 模式，不算在 majority，配置变更就能很快提交了。然而问题是，调整 non-voting 本身就是配置变更操作，这项操作首先就会卡住。
2. 对主节点强依赖。
Raft 论文中描述的配置变更算法都依赖主节点执行，然而实际场景中我们可能遇到无主节点的情况。比如 3 节点副本集，有 2 个节点的机器永久性损坏了，不可能自己选出主节点，此时该如何恢复呢？      
一种简单粗暴的方法，就是将仅剩的节点停掉，然后改配置，再作为单节点的方式重启。     

### 4.4.2 MongoRaft 原理
MongoRaft 的实现原理可以参考作者发布的[论文](https://drops.dagstuhl.de/opus/volltexte/2022/15801/pdf/LIPIcs-OPODIS-2021-26.pdf)，MongoDB 4.4 版本的代码实现可以参考源码中的 [README.md](https://github.com/mongodb/mongo/blob/r4.4.24/src/mongo/db/repl/README.md)。结合论文和代码实现，我认为 MongoRaft 和 Raft 在配置变更流程上有 3 点重大区别：   
1. **Logless**. 结合前面的分析我们看到 Raft 的配置变更流程还是要依赖日志同步，日志同步的快慢或多或少会对配置流程的时长会有影响。而 MongoRaft 采用了“无”日志的方式（也不是整个过程完全没日志，所以要加个引号），使用基于心跳的 Gossip-like 协议进行配置变更同步。在流程上将配置变更和数据同步分开，再保证数据安全的前提下尽量快速进行变更。    
2. **没有照搬 Raft 的 2阶段算法进行配置的安全过渡**。MongoRaft 使用了更加简单巧妙的方式。具体来说，新配置和旧配置必须保证 Quorum 节点有重叠，每次只能有一个 voting节点加入或者删除（对于 non-voting 成员，由于它们不属于 majority(quorum) 的计算范围，因此没有这项限制）。通过这个限制，可以使得协议实现更加简单，但是如果要添加或者删除很多节点，则可能需要发起多次配置。我们可以简单论证一下这种方法的安全性：当前配置C1 和新配置 C2 如果要同时选举产生不同的主节点，则必须通过获得 C1 的主节点需要获得 C1 中大多数节点的同意，C2 的主节点也需要获得 C2 中大多数节点的同意，但是现在 C1 中大多数节点和 C2 中大多数节点必定是有重叠的（QuorumOverlap），这些重叠的节点不会在同一个选举周期内给 2 个不一样的节点投赞成票。因此，通过反证法能够证明不可能同一时刻在 2 个配置中出现 2 个不一样的主节点。
3. **支持 unsafe(force) 模式**。真实业务场景中可能会出现节点损坏较多无法选主的情况，MongoRaft 支持在非主节点发起强制配置变更。Unsafe 模式会跳过很多安全性检查，有数据回滚、丢失的风险。因此，这种模式一般用来应急使用，而不是常规手段。

下面以 MongoDB 4.4 版本的实现进行详细分析。由于 unsafe 模式同 safe 相比主要是跳过了一些检查，因此这里只分析 safe 模式。

#### 配置构成
MongoDB 的配置方法和配置选项可以直接参考[官方文档](https://www.mongodb.com/docs/v4.4/reference/method/rs.reconfig/)，这里不再赘述。

#### 核心流程
配置信息持久化存储在每个 mongod 节点自己的 local.local.system.replset 表中。我们知道 local 库是每个 mongod 本地私有的，不会通过 oplog 同步到其他节点。因此，配置信息不是通过 oplog 同步，而是使用心跳进行同步。    
为了保证变更流程的安全性，除了上述每次添加和删除的节点个数限制之外，执行 reconfig 的主节点还要做 2 项检查（假设当前的配置是 C1,上一个配置是 C0, 即将要变更的配置是 C2）：    
1. 当前配置 C1，已经被复制到了副本集的大多数 voting 成员。
2. 上一个配置 C0 已经提交的数据（复制到大多数 C0 的 voting 成员），在当前配置C1 中也是提交状态，才能进行下一步的状态变更。

其中第 1 项检查保证了 C0 不再有形成大多数的机会。否则在 C1 到 C2 的变更过程中，C0 配置如果也选举了一个主节点，则整个副本集中将同时有  2 个主节点接受写入。    
第 2 项检查保证了已经提交的数据不会因为配置变更而回滚丢失，为了方便理解，参考下面的示意图：     

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/9b10f846-0cf5-480a-9801-c8493846e9fc" width=700>

    
图中所有节点都是 voting 节点，最开始有一条数据在 A, C,E 上提交。节点 E 被删除后，副本集中只有 4 个节点，数据存在于 A 和 C 中，此时不满足大多数条件，但是数据还没有回滚丢失的风险。      
下一步，在没有等待数据同步到 B 时就又进行了一次配置变更，这次增加了一个节点 F。这时问题来了，如果 A 和 C 同时挂掉，会选举 B 或者 D 成为主节点继续接受写入，而 A 和 C 中的数据丢失了。即使 A 和C 重启了恢复正常，也会成为从节点，并将最近提交的数据回滚掉。    
可以看到，如果在第 2 次变更之前，先等待数据同步到 B ，使得数据变更满足大多数节点的提交状态，才能安全的进行下一步配置变更，示意图如下：      
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/1769cb27-1435-461d-851c-b18873e10ff0" width=900>
    
检查完成，满足安全配置变更条件之后，主节点就执行真正的配置变更流程了，示意图如下：     
<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/cbb17664-6e75-407e-afba-be7e512fac95" width=900>
    
主要流程为：    
1. 主节点确保当前配置同步到了大多数 voting 节点，awaitConfigCommitment(currentConfig).     
2. 主节点检查新配置是否合法，以及新配置中节点的状态情况，configValidation & checkQuorumForReconfig.   
3. 主节点将新配置持久化到本地的 local 库中，并更新内存中维护的配置信息。storeLocalConfigDocument & setCurrentRSConfig.   
4. 主节点等待配置同步到大多数节点（提交成功），这里同步是采用心跳的方式，因此最终也是由心跳处理流程唤醒。   
5. 2 个从节点给主节点发（周期性）心跳请求，心跳请求中会携带从节点自己的配置版本号。主节点发现自己的配置版本更高，因此会在心跳响应中塞入新配置，传给从节点。   
6. 2 个从节点接受到更高版本的配置信息，应用到自身节点。即持久化到本地的 local 库，并更新内存中维护的配置信息。storeLocalConfigDocument & setCurrentRSConfig.   
7. 主节点（周期性）给从节点发送心跳请求，发现 2 个从节点都使用了最新配置。认为新配置已经复制到了大多数 voting 节点，已经提交。此时可以给客户端返回 success.    

Mongod 节点内部维护了一个状态机，确保同一时刻主节点上最多只有 1 个 reconfig 操作处于执行中，避免并发操作相互干扰。   
如果在变更流程中出现了节点故障，或者新配置一直没有提交到大多数 voting 节点，则 reconfig 命令可能会失败或者超时。然而在后台新配置可能还是会通过 Gossip-like 协议完成提交。所以客户端在重试之前可以先做一些检查。   

整体变更流程中，心跳发挥了非常重要的作用，包括前期的配置检查 checkQuorumForReconfig, 新配置同步，以及同步情况检查。[心跳请求](https://github.com/mongodb/mongo/blob/r4.4.13/src/mongo/db/repl/repl_set_heartbeat_args_v1.h#L48)和[心跳响应](https://github.com/mongodb/mongo/blob/r4.4.13/src/mongo/db/repl/repl_set_heartbeat_response.h#L50)包含的信息如下：   

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/a322ba73-5dfa-43be-9b5e-1d015c65106c" width=400>

   
副本集内任意2 个节点之间都会有周期性心跳（默认 2 秒），每个节点也可以在一些流程中主动触发心跳，比如节点拓扑发生改变，或者上述变更流程中的 checkQuorumForReconfig 逻辑等。心跳除了探活之外，还会携带 term，configVersion 等信息。如果节点在收到心跳请求时，发现对方的配置版本比自己低，则会在心跳响应中附带上自己完整的配置信息。    

#### 测试分析
我们可以通过下面的测试，验证一下 MongoDB 在主从延迟很大的时候能否快速完成配置变更。   
测试环境为：4.4.13 副本集，3 个 voting 节点，为了方便测试观察，心跳周期设置为 10s（默认 2s）, 选主超时配置为 60s（默认 10s）, 2 个 从节点 slaveDelay 10min（默认没有 slaveDelay, 设置为 hidden 是为了防止主节点切换）. 后台 10 秒 1 次写请求。   
配置变更操作为将一个从节点的 slaveDelay 从 600s 改成 601s.   

首先我们验证正常情况下的配置变更耗时。在执行变更前当前配置已经运行了很长时间，处于提交状态。而且没有切主及 term 变更。   
测试得到的总耗时为 10.902s, 通过在代码中添加日志，看看具体耗时的分布情况：   
1. 第1阶段，确认当前配置复制到了大多数 voting 节点，并且当前 term 的第一条oplog 同步到了大多数，耗时忽略不计（小于 1ms）。   
2. 第 2 阶段，配置检查+大多数节点状态检查+本地配置应用，耗时 811ms。   
3. 第 3 阶段，确认新配置同步到了大多数 voting 节点，耗时 10.091s。   

可见，正常情况下，配置变更流程的耗时主要集中在心跳检查阶段。由于 MongoDB 默认的心跳周期是 2s, 所以正常情况下 2s 左右就能完成配置变更，即使主从延迟有 10分钟也没关系。

再来看看异常情况，主节点重启并继续成为主(term++), 由于 slaveDelay 很大，会在第一阶段阻塞很久。总耗时 10min.   
通过加日志发现，这里的耗时基本都在第 1 阶段，等待当前 term 的第一条日志复制到大多数节点。由于我们测试环境的 slaveDelay 配置为 10 分钟，因此这里也卡了 10 分钟。通过代码我们可以看到第 1 阶段确认 oplog 最小提交时间的判断条件为 std::max(_lastCommittedInPrevConfig, _firstOpTimeOfMyTerm); 

另外，通过测试发现， reconfig 流程也会生成 oplog，这也是为什么要对 logless 的“无”日志变更加上引号的原因：   

<img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/31511f6f-671b-46f1-abcd-9c06275bcecb" width=700>

 
同样，出现了选主及 term 变更，也会生成一条 oplog, 也就是上述 _firstOpTimeOfMyTerm 的依据。   

#### 小结
1. Raft 协议通过动态变更算法保证了配置变更流程中的可用性，并通过 2 阶段的方式保证安全。   
2. MongoRaft 在 Raft 基础上，借助心跳机制实现配置变更和数据复制分离，能够很大程度上缓解主从延迟大带来的配置变更耗时长的问题。并通过 QuorumCheck 的机制在保证安全性的同时简化了配置变更算法。   
3. MongoRaft 提供了 unsafe(force) 模式，能够在非主节点上实现强制变更，能够在极端情况下快速完成服务恢复。   


## 4.5 一致性讨论

# 5. 总结

# 6. 参考文档
1. Design and Analysis of a Logless Dynamic Reconfiguration Protocol， https://drops.dagstuhl.de/opus/volltexte/2022/15801/pdf/LIPIcs-OPODIS-2021-26.pdf
2. In Search of an Understandable Consensus Algorithm (Extended Version)，https://raft.github.io/raft.pdf
3. https://raft.github.io/
4. https://github.com/mongodb/mongo/blob/r4.4.24/src/mongo/db/repl/README.md
5. 共识协议的技术变迁，https://mp.weixin.qq.com/s/UY9TPMcuf0O7xS0kuXTcVw


