# 1. 导语
Oplog 是 MongoDB 中一个特殊的、存储了变更记录的表，在主从数据复制、数据持久化保障、按时间点备份回档、changeStream 变更流、操作追溯等各方面都有着举足轻重的作用。因此，其实现的好不好，直接关系到了 MongoDB 的产品竞争力。   

在上文介绍 MongoRaft 时，已经说明了 oplog 的复制流程以及在数据持久化中发挥的作用，本文不再赘述。但是关于 oplog仍有很多其他方面的细节并未做分析。因此，本文会聚焦 oplog 实现中的核心问题进行分析，包括以下内容：   
1. Oplog 格式。分析 oplog 中每条文档会包含哪些字段，以及各自发挥的作用。   
2. 幂等性保证。存储系统中日志对于幂等性的需求并不罕见，那么MongoDB 在支持了各种操作算子的背景下，如何保证 oplog 的幂等性呢？   
3. 可见性判断。主从节点上都是并发写 oplog，都存在临时的 oplog 空洞，如何保证存在空洞的 oplog 不会被拉取到呢？   
4. 性能。分析 oplog 表如何在无索引的情况下保证高效的查询性能，以及如何优化oplog 表的删除机制，来避免对用户写入性能的影响。   
5. 回放。分析 oplog 的回放流程，探讨 MongoDB 内核以及外部工具如何使用 oplog。   

不同内核版本之间可能在 oplog 格式上存在差异，比如 4.2 版本引入了分布式事务相关的 oplog，取消了 hash 值作为每条 oplog 的 ID。   
本文的讨论基于 4.2.24 版本内核代码。

# 2. 格式
Oplog 是 local 库中一个特殊的固定大小的表，逻辑上可以看做是一个环形队列。里面的文档按照时间戳进行组织，当空间不足时，会自动删除最老的文档。和普通的用户表一样， oplog 表也支持各种过滤条件的查询、排序、映射等操作。   
Oplog 中每一条文档（oplog entry）记录了一次变更操作，文档中包含的字段相对比较固定，可以参考 [oplog_entry.idl](https://github.com/mongodb/mongo/blob/r4.2.24/src/mongo/db/repl/oplog_entry.idl) 代码中的定义，列举如下：    
|字段名|类型|是否可选|备注|
|:--|:--|:--|:--|
|ts|timestamp|必选|时间戳，由 int32 的 unix 秒级时钟和 int32 的秒内自增计数器共同组成。可以当做一个 int64 整数，是 **oplog 表的主键**。|
|t|long|必选|MongoRaft 协议中的 term。未引入 MongoRaft 协议的老版本没有这个字段。|
|h|long|4.2 版本开始逐步废弃|这条 oplog 文档的摘要。兼容4.0以及更老的版本，新版本这个字段为 0。|
|v|int64|必选|Oplog entry 格式的版本，默认为1。|
|wall|date|必选|机器的毫秒级时间。|
|op|string|必选|表示命令的类型，包括："i" -> insert 操作，"u" -> update 操作，"d" -> delete 操作， “c” -> 其他命令，比如建表，"n" -> noop, 没有变更操作时进行时钟推进。|
|ns|string|必选|表空间，一般是 “库名.表名”。如果只涉及库，不涉及具体的表，则为“库名.$cmd”。|
|ui|uuid|可选|表的 UUID 信息，如果对表进行了重命名，其 UUID 不变。|
|o|object|必选|执行的操作。比如对于 insert 操作，这个字段就包含了插入的文档。|
|o2|object|可选|操作的附加信息。比如对于 update 操作，除了执行的操作之外，还需要查询条件（对哪条文档执行的操作）。|
|b|bool|可选|是否为 upsert（update 自动转 insert），兼容 3.6 及更老的版本。|
|fromMigrate|bool|可选|是否为 chunk 迁移产生的，存在于分片集群中。|
|stmtId|int32|可选|产生这个oplog entry的 statementId, 一个事务可能对应多个变更操作，每个操作有独立的 statementId。|
|prevOpTime|optime|可选|同一个事务中，上一条 oplog 的 optime。通过这项信息，可以把事务的多个 oplog 串联起来。|
|preImageOpTime|optime|可选|prevImage 信息存储在另外一条 oplog entry 中，这个字段存的是其“指针”信息。|
|postImageOpTime|optime|可选|本次 update 操作执行之后，文档是啥样（postImage）。postImage 信息存储在另外一条 oplog entry 中，这个字段存的是其“指针”信息。|
|needsRetryImage|string|可选|可以是 "preImage" 或者 "postImage"。|

# 3. 幂等性
## 3.1 为什么要保证幂等性
当我们使用 mongdump 工具或者 find+getmore 命令进行全表扫描时，默认情况下读到的并非某个时间点的一致性数据（除非在高版本内核主动指定 readConcern 为 snapshot， 不过这种方式会带来资源消耗风险）。为了防止一个批量扫描请求长时间锁住太多资源（维护老版本的开销），MongoDB 的执行模式为定期 yield 释放老 snapshot，然后创建新 snapshot 继续扫描。参考《[Tunable Consistency in MongoDB](https://www.vldb.org/pvldb/vol12/p2071-schultz.pdf)》论文中的说明：   
<p align="center">
  <img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/67f71ba0-e233-4866-aeb8-f990483a96b1" width=350>
</p>

定期释放snapshot 能够降低长期维护老数据版本造成的内存压力，但是带来的数据一致性问题需要通过其他方式来解决。对于 mongodump 来说，可以通过[指定 --oplog 参数](https://www.mongodb.com/docs/v4.2/tutorial/backup-and-restore-tools/#create-backups-using-oplogs)来备份从扫描开始到结束这段时间的所有 oplog，来达到一致性备份的目的，示意图如下：    
<p align="center">
  <img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/903a9cec-59e8-4e12-8823-ec7b3bf48f64" width=450>
</p>

1. t1时刻，mongodump 开始全量扫描，将第 1 条文档 {a:1} 备份下来。   
2. t2 时刻，扫描到第2 条文档，刚好在此之前用户将这条文档的 b 字段进行了加 1 操作，全量备份得到 {b: 2}，对这条文档的操作会记录 oplog。   
3. t3 时刻，扫描到第 3 条文档，刚好在此之前用户将这条文档的 c 字段进行了加 2 操作，全量备份得到 {c: 3}，但与此同时对第1 条文档{a: 1}的修改不会再扫描一次。t3 时刻对第 1 条和第 3 条文档的操作都会记录 oplog。   

可以看到，全量备份结束后，全量备份数据和 t3 时刻数据库的状态并不一致。但是在回放时，如果结合 oplog 的增量回放，就能准确地将数据库回档到 t3 时刻的一致性状态。   
细心的读者可能已经发现，在回放 oplog 时可能会有操作重复执行的情况。比如上例的全量备份中，第 2 条文档已经是修改过的 {b:2}，但是在 oplog 回放时可是会执行一次这条文档的修改操作。**如果 oplog 本身不能保证幂等性，则上述操作重复执行的情况可能导致数据不正确。**  

除了 mongodump，还有很多流程依赖 oplog 的幂等性，比如跨集群的 DTS 数据同步工具，内核中的 [initial sync](https://github.com/mongodb/mongo/blob/r4.4.24/src/mongo/db/repl/README.md#initial-sync) 逻辑同步流程等。因此，oplog 对于幂等性的要求是毋庸置疑的。

## 3.2 如何保证幂等性
Oplog 实现幂等性的方法，就是存储变更操作后的结果，而不仅是具体的变更动作。比如对文档  {a: 1} 的 "a" 字段做加 1  操作，则 oplog 中记录 {$set: {a: 2}} 。    

对于 insert操作，在 "o" 字段中记录插入的完成文档，例如插入一条文档 {"_id" :10, "a": 5}，得到的 oplog 为：   
```
{ "ts" : Timestamp(1702090192, 1), "t" : NumberLong(1), "h" : NumberLong(0), "v" : 2, "op" : "i", "ns" : "db1.coll1", "ui" : UUID("65a840e8-ab6d-4f56-9daf-fe1ccc33d052"), "wall" : ISODate("2023-12-09T02:49:52.960Z"), "o" : { "_id" : 10, "a" : 5 } }
```

对于 delete操作，只需要记录文档的 "_id" 即可，例如删除上一步插入的文档，得到的 oplog 为：    
```
{ "ts" : Timestamp(1702090210, 1), "t" : NumberLong(1), "h" : NumberLong(0), "v" : 2, "op" : "d", "ns" : "db1.coll1", "ui" : UUID("65a840e8-ab6d-4f56-9daf-fe1ccc33d052"), "wall" : ISODate("2023-12-09T02:50:10.013Z"), "o" : { "_id" : 10 } }
```

对于 update 操作，则情况要复杂一点。 MongoDB 支持多种 update 方式：   
- [Replace](https://www.mongodb.com/docs/v4.2/tutorial/update-documents/) 方式，客户端将要更新的文档准备好，然后使用**整文档替换**的方式进行 update，有点把  MongoDB 当作 KV 存储使用的感觉。比如将文档 {"_id":0, "a":1, "b":2, "c":3} 替换为 {"_id":0, "a":1, "b":2, "c":4}，则执行 replace 更新的方式是 db.coll1.update({"_id":0}, {"_id":0, "a":1, "b":2, "c":4})， 得到的 oplog 如下， "o" 字段中包含了整条文档，而不只是修改过的 "c" 字段：
```
{ "ts" : Timestamp(1702090827, 1), "t" : NumberLong(1), "h" : NumberLong(0), "v" : 2, "op" : "u", "ns" : "db1.coll1", "ui" : UUID("65a840e8-ab6d-4f56-9daf-fe1ccc33d052"), "o2" : { "_id" : 0 }, "wall" : ISODate("2023-12-09T03:00:27.142Z"), "o" : { "_id" : 0, "a" : 1, "b" : 2, "c" : 4 } }
```
- [Pipeline](https://www.mongodb.com/docs/v4.2/tutorial/update-documents-with-aggregation-pipeline/) 方式，4.2 内核版本开始支持，支持更高级的语法在MongoDB 服务侧对文档进行更新。这种方式下，oplog 中存储的也是整条新文档，和 Replace 方式相同。
- [Operator](https://www.mongodb.com/docs/v4.2/reference/operator/update/) 方式。MongoDB 支持十几个算子，在服务侧对指定文档的一个或多个字段进行**局部更新**。这种方式下，oplog 中只需要存储涉及到的字段的操作结果。相比 Replace 方式，Operator 方式的网络传输流量更小、占用的 oplog 和 journal 空间更小。比如将文档 {"_id":0, "a":1, "b":2, "c":3} 中的 "c" 字段改成 5，则执行局部更新的命令是  db.coll1.update({"_id":0}, {$set:{"c":5}})，得到的 oplog 如下，只包含修改过的字段：   
```
{ "ts" : Timestamp(1702091364, 1), "t" : NumberLong(1), "h" : NumberLong(0), "v" : 2, "op" : "u", "ns" : "db1.coll1", "ui" : UUID("65a840e8-ab6d-4f56-9daf-fe1ccc33d052"), "o2" : { "_id" : 0 }, "wall" : ISODate("2023-12-09T03:09:24.932Z"), "o" : { "$v" : 1, "$set" : { "c" : 5 } } }
```

Operator 方式下的 oplog 构造流程相对较复杂。为了弄清其 oplog 构造流程，我们需要先看看 operator 更新条件是如何执行的。   
由于 MongoDB 的文档模型中存在 Object 和 Array 嵌套，MongoDB 在请求解析阶段会先将更新语句解析成一个前缀树，比如对嵌套字段 "a.b.c" 和 "a.b.d" 的更新具有相同的前缀 "a.b"。前缀树的根节点就是对某个字段的具体变更操作，比如 $inc $mul 算数操作等。    
参考[内核代码](https://github.com/mongodb/mongo/tree/r4.2.24/src/mongo/db/update)，前缀树的节点定义关系如下：   
<p align="center">
  <img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/1418abba-22f9-45fd-a11c-0bcffe23efdc" width=800>
</p>

以 update(<queryFilter>, {$set:{"a.b": 5, "c":6}, $inc:{"a.c":1}}) 这条语句的执行流程为例，MongoDB 首先会根据解析更新操作生成如下前缀树（updateTree）：   
<p align="center">
  <img src="https://github.com/pengzhenyi2015/MongoDB-Kernel-Study/assets/16788801/3e37c3ed-4c57-4a9a-9c4a-9fab9708f670" width=400>
</p>

执行计划的构造流程为：先使用 queryFilter 构造 [queryStage](https://github.com/mongodb/mongo/blob/r4.2.24/src/mongo/db/query/get_executor.cpp#L1086-L1094)，然后基于此构造 [updateStage](https://github.com/mongodb/mongo/blob/r4.2.24/src/mongo/db/query/get_executor.cpp#L1099-L1103)。在 queryStage 阶段查找出需要修改的文档，然后在 updateStage 阶段对文档进行修改。    
而 updateStage 的执行流程，本质上就是对上述 updateTree 中各个叶子节点执行 apply 的流程。在执行 apply 操作时，会传入 logBuilder 进行 oplog 的流式构造。以 {$inc: {"a.c": 1}} 为例，会在 ArithmeticNode 的 apply 流程中对 "a.c" 字段进行 “加1” 操作，然后将操作后的 newValue 传递给 logBuilder 转换为 {$set : {"a.c": newValue}} 合并到最终的 oplog 中。   

# 4. 可见性

# 5. 性能优化

# 6. 回放

# 7. 总结

# 参考文档
